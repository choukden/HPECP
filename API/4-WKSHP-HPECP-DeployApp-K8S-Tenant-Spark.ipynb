{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPE Container Platform API series  - Lab 3 (Spark)\n",
    "## Launching cloud-native stateless applications and non-cloud-native stateful applications, programmatically through REST API calls, as a Kubernetes Tenant user.\n",
    "\n",
    "\n",
    "**Requirements:**\n",
    "- HPE Container Platform deployment\n",
    "- IP address of FQDN of the HPE Container Platform's controller host\n",
    "- a Kubernetes tenant user account   \n",
    "\n",
    "**Utilities:**   \n",
    "- cURL  \n",
    "- Jupyter Notebook server with bash kernel installed\n",
    "- kubectl, kubectl hpecp plug-in\n",
    "\n",
    "**Definitions:**\n",
    "- *HPE Container Platform* is an enterprise-grade container platform designed to deploy both cloud-native and non-cloud-native applications whether on-premises, at the edge, in multiple public clouds, or in a hybrid model. This makes the HPE Container Platform ideal for helping application developers and data scientists accelerate their application development and deployment on **containers**, on-demand through a self-service portal and a RESTful API that surfaces programmable access. To learn more about HPE Container Platform visit the [HPE DEV portal](https://developer.hpe.com/platform/hpe-container-platform/home) and check out the blog articles.\n",
    "\n",
    "- *tenant:* A tenant is a group of users created by the platform administrator. A tenant can represent for example, an office location, a business unit, an organization, a project, an application. A tenant is allocated a set of resources (CPU/GPU, RAM, Storage, App Store images, Kubernetes cluster) by the platform administrator. All the resources used by a tenant are not shared with other tenants. A tenant user is granted the role of member or admin for the tenant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPE Container Platform provides two types of tenants:  \n",
    "* Big data, AI/ML tenants that exist within the context of HPE Container Platform. This type of tenants are also known as **EPIC** (Elastic Private Instant Cluster) tenants.\n",
    "* Kubernetes tenants that exist within the context of one or more Kubernetes clusters managed by HPE Container Platform.\n",
    "  \n",
    "Here, in this lab part, I will cover how **Kubernetes tenant** users can deploy, using REST API, both cloud-native stateless, microservices applications, and non-cloud-native distributed stateful AI/analytics **KubeDirector** applications on **Kubernetes** cluster managed by HPE Container Platform. Tenant users will then use kubectl to interact directly with the Kubernetes cluster in the context of their tenant.\n",
    "\n",
    "KubeDirector, also known as Kubernetes Director, is a key component of HPE Container Platform. KubeDirector is an open source project initiated by HPE (BlueData) that enables the running of non-cloud-native stateful analytics workloads on Kubernetes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The HPE Container Platform API Reference\n",
    "The HPE Container Platform REST API allows you to achieve multiple actions programmatically, from performing administrative tasks, deploying cloud-native and non-cloud-native applications to scoring trained Machine Learning models.\n",
    "\n",
    "Before you can call the HPE Container Platform API, you need to know what calls can be placed. The REST API reference documentation describes each object type, along with the supported operations, request input parameters, response model and response codes. \n",
    "To access the REST API reference documentation, obtain the IP address or hostname of the current active HPE Container Platform controller host from the administrator of the platform. Then in a web browser, navigate to the following URL:\n",
    "\n",
    "``` \n",
    "http(s)://[Controller-IP-address-name]/apidocs\n",
    "```\n",
    "\n",
    "All the REST API calls are in the form: \n",
    "``` \n",
    "An HTTP VERB such as (GET , POST, DELETE, PUT, PATCH, UPDATE),  \n",
    "A target API object URL: http(s)://[Controller-IP-address]:8080/api/v2/[object]\n",
    "```\n",
    "\n",
    "## Session Authentication in a multi-tenant environment\n",
    "With the exception of some API calls, most of the REST API calls you can do against the HPE Container Platform API requires authentication. HPE Container Platform uses a *‘session location’* to use as operation context. In a multi-tenant environment, you request an authentication session location by issuing an authentication request in the following form:\n",
    "* Call the API to request a new login session, providing username/password credentials as well as the Tenant name in the JSON body.  The user must be a valid tenant user credentials with a role (member or admin) in the requested tenant. \n",
    "* Extract the resource path of the created *session location* object from the JSON response header,\n",
    "* For each subsequent call, set a new HTTP Header with its key set to *X-BDS-SESSION* and its value set to the session location value and used as the *working tenant* context. \n",
    "\n",
    "``` \n",
    "Note: the session location will expire after 24 hours. \n",
    "```   \n",
    "\n",
    "If you are not already familiar with REST API calls, I encourage you to check-out the [Understanding API basics and the value they provide](https://developer.hpe.com/blog/understanding-api-basics-and-the-value-they-provide) blog on HPE Developer Community portal. It explains you REST API concepts such as HTTP verbs you call against the API, the headers, and payloads used when making API calls.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cURL:** You will use cURL to make API requests. Information on cURL can be found [here](https://curl.haxx.se/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the environment.\n",
    "\n",
    "**IMPORTANT: Before running the next cells, please make sure to adjust the environment variables below according to your Student ID, tenant username and password.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# environment variables to be adjusted by the student\n",
    "#\n",
    "student=\"denis\" # your Jupyter Notebook student Identifier (i.e.: student<xx>)\n",
    "username=\"demouser\" # your tenant login credentials - username and password (it matches your Notebook Student account)\n",
    "password=\"password\"\n",
    "#\n",
    "# fixed environment variables setup by the HPE CP administrator\n",
    "#\n",
    "controller_endpoint=\"controller.hpedevlab.net:8080\"\n",
    "controller_host=\"controller.hpedevlab.net\"\n",
    "tenantname=\"K8sHackTenant\"\n",
    "k8sClusterId=\"1\"  #this is the K8s Cluster Id provided by the HPE CP admisnistrator and assigned to your K8s tenant.\n",
    "helloWorldApp=\"hello-world-app.yaml\" # the application manifest you will deploy in this lab\n",
    "tensorFlowApp=\"tensorflow-notebook-config-cluster.yaml\" # the kubedirector application cluster configuration\n",
    "sparkApp=\"spark221e2-stor-config-cluster.yaml\" # the kubedirector application cluster configuration Spark221e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authenticate as Tenant user in the specified tenant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your session location:  /api/v2/session/242bf46b-926c-426e-88d3-45c42fb51a20\n",
      "This is your session_Id: 242bf46b-926c-426e-88d3-45c42fb51a20\n"
     ]
    }
   ],
   "source": [
    "sessionlocation=$(curl -k -i -s --request POST \"https://${controller_endpoint}/api/v2/session\" \\\n",
    "--header 'Accept: application/json' \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data-raw '{\n",
    "\"name\": \"'\"$username\"'\",\n",
    "\"password\": \"'\"$password\"'\",\n",
    "\"tenant_name\": \"'\"$tenantname\"'\"\n",
    "}' | grep Location | awk '{print $2}' | tr -d '\\r') #we remove any cr that might exist\n",
    "echo \"This is your session location: \" $sessionlocation\n",
    "SessionId=$(echo $sessionlocation | cut -d'/' -f 5) # extract sessionId for later, for logout\n",
    "echo \"This is your session_Id:\" $SessionId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a quick check to ensure you can make REST API calls within your tenant working context:\n",
    "Here you will fetch information about your session you have just established."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"_links\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"self\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"href\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"/api/v2/session/242bf46b-926c-426e-88d3-45c42fb51a20\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"all_sessions\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"href\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"/api/v2/session\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"user\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"/api/v1/user/60\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"user_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"demouser\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"tenant\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"/api/v1/tenant/5\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"tenant_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"K8sHackTenant\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"role\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"/api/v1/role/3\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"role_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Member\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"expiry\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"2020-4-17 00:19:58\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"expiry_time\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1587075598\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"is_site_admin_view\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"is_cluster_superuser\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "curl -k -s --request GET \"https://${controller_endpoint}/api/v2/session/${SessionId}\" \\\n",
    "--header \"X-BDS-SESSION: $sessionlocation\" \\\n",
    "--header 'Accept: application/json' \\\n",
    "--header 'Content-Type: application/json' | jq  #using jq to pretty print the JSON reponse of the API call "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a simple cloud-native stateless application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -1- Deploy Hello World containerized application\n",
    "You will deploy a simple Hello World application on the Kubernetes cluster made available to your tenant. The REST API (POST) call requires the **kubectl** operation type (create or apply) and the application manifest (YAML file that describes the attributes of the application) in a base64 encoded form.  \n",
    "\n",
    "As you are all sharing the same tenant context and Kubernetes cluster resources, let's make sure your application deployment name will be unique among the tenant users. Here we replace the string \"example\" with your \"username\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: apps/v1\n",
      "kind: Deployment\n",
      "metadata:\n",
      "  name: hello-world-demouser\n",
      "spec:\n",
      "  selector:\n",
      "    matchLabels:\n",
      "      run: load-balancer-demouser\n",
      "  replicas: 2\n",
      "  template:\n",
      "    metadata:\n",
      "      labels:\n",
      "        run: load-balancer-demouser\n",
      "    spec:\n",
      "      containers:\n",
      "        - name: hello-world-demouser\n",
      "          image: gcr.io/google-samples/node-hello:1.0\n",
      "          ports:\n",
      "            - containerPort: 8080\n",
      "              protocol: TCP\n",
      "---\n",
      "apiVersion: v1\n",
      "kind: Service\n",
      "metadata:\n",
      "  name: hello-world-service-demouser\n",
      "spec:\n",
      "  selector:\n",
      "    run: load-balancer-demouser\n",
      "  ports:\n",
      "  - name: http-hello\n",
      "    protocol: TCP\n",
      "    port: 8080\n",
      "    targetPort: 8080\n",
      "  type: NodePort\n"
     ]
    }
   ],
   "source": [
    "sed -i \"s/example/${username}/g\" $helloWorldApp\n",
    "cat $helloWorldApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the application description file in base64\n",
    "myapp=$(base64 $helloWorldApp)\n",
    "#echo $myapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/hello-world-demouser created\n",
      "service/hello-world-service-demouser created"
     ]
    }
   ],
   "source": [
    "curl -k -s --request POST \"https://${controller_endpoint}/api/v2/k8scluster/${k8sClusterId}/kubectl\" \\\n",
    "--header \"X-BDS-SESSION: $sessionlocation\" \\\n",
    "--header 'Accept: application/json' \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data-raw '{\n",
    "\"data\": \"'\"$myapp\"'\",\n",
    "\"op\": \"apply\"\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a minute or so, you should get the message *Deployment and service created* on the Kubernetes cluster.   \n",
    "\n",
    "You will now directly interact with the Kubernetes cluster using **kubectl** (the command line configuration tool for Kubernetes).  \n",
    "\n",
    "In the next steps, you will use kubectl commands in the context of your tenant user account and get the service endpoints of your application to connect to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -2- Establish the kubectl authenticated context using kubectl hpecp plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kubectl hpecp plug-in is an extension of the standard kubectl command line. The plugin handles HPECP login and session token management. It is used to establish **HPECP-authenticated** kubectl requests to HPECP-managed Kubernetes services.   \n",
    "\n",
    "Let's get the kubeconfig file for your working tenant context. The kubeconfig file contains kubernetes context that tenant users can interact with, based on their assigned role (tenant admin or tenant member)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Retrieved new Kube Config from HPECP server at controller.hpedevlab.net:8080.\n",
      "The KUBECONFIG environment variable HAS NOT been set.\n",
      "Your current session WILL NOT have the new configuration.\n",
      "To persist these changes by loading all current Kube Config\n",
      "values into your default Kube Config file, run the\n",
      "following command:\n",
      "\n",
      "    KUBECONFIG=\"/home/denis/.kube/.hpecp/controller.hpedevlab.net/config:/home/denis/.kube/config-backup\" kubectl config view --raw > /home/denis/.kube/config\n",
      "\n",
      "To persist these changes by changing your local KUBECONFIG\n",
      "environment variable, run the following command:\n",
      "\n",
      "    export KUBECONFIG=\"/home/denis/.kube/.hpecp/controller.hpedevlab.net/config\"\n",
      "\n",
      "CAUTION - both of these commands will OVERWRITE your current\n",
      "Kube Config settings. This is probably what you want, but\n",
      "to confirm that this command will not break your system,\n",
      "run the following command to view the resulting Kube\n",
      "Config file:\n",
      "\n",
      "    KUBECONFIG=\"/home/denis/.kube/.hpecp/controller.hpedevlab.net/config:/home/denis/.kube/config\" kubectl config view\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#kubectl version --client\n",
    "#kubectl hpecp version\n",
    "kubectl hpecp refresh --insecure-skip-tls-verify ${controller_host} --hpecp-user=\"${username}\" --hpecp-pass=\"${password}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/denis/.kube/.hpecp/controller.hpedevlab.net/config\n"
     ]
    }
   ],
   "source": [
    "#define the Kubeconfig file as a shell environment variable\n",
    "export KUBECONFIG=\"/home/${student}/.kube/.hpecp/${controller_host}/config\"\n",
    "echo $KUBECONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your working tenant context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "clusters:\n",
      "- cluster:\n",
      "    insecure-skip-tls-verify: true\n",
      "    server: https://gateway1.etc.fr.comm.hpecorp.net:9500\n",
      "  name: k8scluster1\n",
      "contexts:\n",
      "- context:\n",
      "    cluster: k8scluster1\n",
      "    namespace: k8shacktenant\n",
      "    user: HPECP-demouser\n",
      "  name: k8scluster1-K8sHackTenant-demouser\n",
      "current-context: k8scluster1-K8sHackTenant-demouser\n",
      "kind: Config\n",
      "preferences: {}\n",
      "users:\n",
      "- name: HPECP-demouser\n",
      "  user:\n",
      "    exec:\n",
      "      apiVersion: client.authentication.k8s.io/v1beta1\n",
      "      args:\n",
      "      - hpecp\n",
      "      - authenticate\n",
      "      - gateway1.etc.fr.comm.hpecorp.net:8080\n",
      "      - --hpecp-user=demouser\n",
      "      - --hpecp-token=/api/v2/session/0c9ebaa8-0c00-4049-adcb-de43aba96e8b\n",
      "      - --hpecp-token-expiry=1587074333\n",
      "      - --force-reauth=false\n",
      "      - --insecure-skip-tls-verify=true\n",
      "      command: kubectl\n",
      "      env: null\n"
     ]
    }
   ],
   "source": [
    "kubectl config view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -3- Get the POD and Services for your deployed application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod/hello-world-demouser-7d79c6c7dc-b2s2h   1/1     Running   0          116s\n",
      "pod/hello-world-demouser-7d79c6c7dc-bcn8f   1/1     Running   0          116s\n",
      "service/hello-world-service-demouser   NodePort   10.96.237.190   <none>        8080:30575/TCP   116s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pod,service | grep ${username}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:                     hello-world-service-demouser\n",
      "Namespace:                k8shacktenant\n",
      "Labels:                   hpecp.hpe.com/hpecp-internal-gateway=true\n",
      "Annotations:              hpecp-internal-gateway/8080: gateway1.etc.fr.comm.hpecorp.net:10002\n",
      "                          kubectl.kubernetes.io/last-applied-configuration:\n",
      "                            {\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"annotations\":{},\"name\":\"hello-world-service-demouser\",\"namespace\":\"k8shacktenant\"},\"spec\"...\n",
      "Selector:                 run=load-balancer-demouser\n",
      "Type:                     NodePort\n",
      "IP:                       10.96.237.190\n",
      "Port:                     http-hello  8080/TCP\n",
      "TargetPort:               8080/TCP\n",
      "NodePort:                 http-hello  30575/TCP\n",
      "Endpoints:                10.192.0.195:8080,10.192.1.72:8080\n",
      "Session Affinity:         None\n",
      "External Traffic Policy:  Cluster\n",
      "Events:\n",
      "  Type    Reason  Age   From         Message\n",
      "  ----    ------  ----  ----         -------\n",
      "  Normal  HpeCp   115s  hpecp-agent  Created HPECP K8S service\n"
     ]
    }
   ],
   "source": [
    "kubectl describe service hello-world-service-${username}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -4- Get the service endpoints\n",
    "HPE Container Platform automatically maps the NodePort Service endpoint to the HPE Container Platform gateway (proxy) host.\n",
    "Access to application services running in containers is proxied via the gateway host and a port number greater than 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your application service endpoint is: https://gateway1.etc.fr.comm.hpecorp.net:10002\n"
     ]
    }
   ],
   "source": [
    "myservice=\"hello-world-service-\"${username}\n",
    "appURL=$(kubectl describe service/\"${myservice}\" | grep gateway1 | awk '{print $3}')\n",
    "myapp_endpoint=\"https://${appURL}\"\n",
    "echo \"Your application service endpoint is: \"$myapp_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -5- Check your application is responding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Kubernetes!"
     ]
    }
   ],
   "source": [
    "curl -k -s \"${myapp_endpoint}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -6- Delete your stateless application deployment\n",
    "Delete your application deployment and services using the REST API (POST) call below. The REST API call requires the **kubectl** operation type (delete) and the application manifest in a base64 encoded form.\n",
    "After a minute or so, you should get the message: deployment deleted and service deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"hello-world-demouser\" deleted\n",
      "service \"hello-world-service-demouser\" deleted"
     ]
    }
   ],
   "source": [
    "curl -k -s --request POST \"https://${controller_endpoint}/api/v2/k8scluster/${k8sClusterId}/kubectl\" \\\n",
    "--header \"X-BDS-SESSION: $sessionlocation\" \\\n",
    "--header 'Accept: application/json' \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data-raw '{\n",
    "\"data\": \"'\"$myapp\"'\",\n",
    "\"op\": \"delete\"\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a KubeDirector Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPE has been working within the open source Kubernetes community to add capabilities that enable the running of **stateful** analytics workloads (data-intensive distributed applications) on Kubernetes.  The open source project is known as **Kubernetes Director** or **KubeDirector** for short.   \n",
    "With KubeDirector, enterprises can deploy all their enterprise applications on a common Kubernetes framework.\n",
    "KubeDirector is deployed as a custom controller (aka an operator) by default on every Kubernetes cluster managed by the HPE Container Platform.\n",
    "\n",
    "For more information about KubeDirector, check out the HPE DEV portal [here](https://developer.hpe.com/platform/hpe-container-platform/home)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -1- List the installed KubeDirector Application\n",
    "In the current release of HPE Container Platform, the Kubernetes cluster managed by HPE Controller platform has three (3) pre-configured KubeDirector Application types installed out of the box. A tenant user who would access the HPE Container Platform portal UI could see it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pictures/HPECP-KubeDirectorApp-GUI.png\" height=\"800\" width=\"600\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the list of KubeDirector Applications using kubectl command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                  AGE\n",
      "centos7x              22d\n",
      "ml-jupyter-notebook   22d\n",
      "spark221e2            22d\n"
     ]
    }
   ],
   "source": [
    "kubectl get kubedirectorapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A KubeDirector Application describes an application metadata: the service roles and endpoints, the Docker images, the app setup packages, the cardinality (minimum number of members in a role), and if appropriate, the root file system directories (e.g.: /etc, /bin, /opt, /var, /usr) of the containers to persist beyond the life span of the containers. This means stateful applications that require to write data to their root file systems can now successfully run on Kubernetes. Let's inspect a couple of KubeDirector Application types: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         ml-jupyter-notebook\n",
      "Namespace:    k8shacktenant\n",
      "Labels:       <none>\n",
      "Annotations:  token:\n",
      "                execute this command to get the authentication token 'kubectl exec <pod-name> jupyter notebook list' and use this token in Jupyter noteboo...\n",
      "API Version:  kubedirector.hpe.com/v1beta1\n",
      "Kind:         KubeDirectorApp\n",
      "Metadata:\n",
      "  Creation Timestamp:  2020-03-24T08:25:15Z\n",
      "  Generation:          2\n",
      "  Resource Version:    2874116\n",
      "  Self Link:           /apis/kubedirector.hpe.com/v1beta1/namespaces/k8shacktenant/kubedirectorapps/ml-jupyter-notebook\n",
      "  UID:                 cb7a6132-f321-45d6-81f5-635f0b79e61e\n",
      "Spec:\n",
      "  Config:\n",
      "    Role Services:\n",
      "      Role ID:  controller\n",
      "      Service I Ds:\n",
      "        jupyter-nb\n",
      "    Selected Roles:\n",
      "      controller\n",
      "  Config Schema Version:   7\n",
      "  Default Config Package:  <nil>\n",
      "  Distro ID:               bluedata/tensorflow\n",
      "  Label:\n",
      "    Description:  TensorFlow GPU with Jupyter notebook\n",
      "    Name:         TensorFlow + Jupyter\n",
      "  Roles:\n",
      "    Cardinality:     1\n",
      "    Config Package:  <nil>\n",
      "    Id:              controller\n",
      "    Image Repo Tag:  tensorflow/tensorflow:latest-gpu-py3-jupyter\n",
      "    Min Resources:\n",
      "      nvidia.com/gpu:  0\n",
      "  Services:\n",
      "    Endpoint:\n",
      "      Is Dashboard:  true\n",
      "      Path:          /\n",
      "      Port:          8888\n",
      "      URL Scheme:    http\n",
      "    Id:              jupyter-nb\n",
      "    Label:\n",
      "      Name:          Jupyter Notebook\n",
      "  Systemd Required:  true\n",
      "  Version:           2.0\n",
      "Events:              <none>\n"
     ]
    }
   ],
   "source": [
    "kubectl describe kubedirectorapp ml-jupyter-notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         spark221e2\n",
      "Namespace:    k8shacktenant\n",
      "Labels:       <none>\n",
      "Annotations:  <none>\n",
      "API Version:  kubedirector.hpe.com/v1beta1\n",
      "Kind:         KubeDirectorApp\n",
      "Metadata:\n",
      "  Creation Timestamp:  2020-03-24T08:25:15Z\n",
      "  Generation:          1\n",
      "  Resource Version:    981021\n",
      "  Self Link:           /apis/kubedirector.hpe.com/v1beta1/namespaces/k8shacktenant/kubedirectorapps/spark221e2\n",
      "  UID:                 753618be-1edf-470c-bff5-385d0e76fafe\n",
      "Spec:\n",
      "  Config:\n",
      "    Role Services:\n",
      "      Role ID:  controller\n",
      "      Service I Ds:\n",
      "        ssh\n",
      "        spark\n",
      "        spark-master\n",
      "        spark-worker\n",
      "      Role ID:  worker\n",
      "      Service I Ds:\n",
      "        ssh\n",
      "        spark-worker\n",
      "      Role ID:  jupyter\n",
      "      Service I Ds:\n",
      "        ssh\n",
      "        jupyter-nb\n",
      "    Selected Roles:\n",
      "      controller\n",
      "      worker\n",
      "      jupyter\n",
      "  Config Schema Version:  7\n",
      "  Distro ID:              bluedata/spark221e2\n",
      "  Label:\n",
      "    Description:  Spark 2.2.1 with Jupyter notebook\n",
      "    Name:         Spark 2.2.1 + Jupyter\n",
      "  Roles:\n",
      "    Cardinality:  1\n",
      "    Config Package:\n",
      "      Package URL:   file:///opt/configscripts/appconfig-2.6.tgz\n",
      "    Id:              controller\n",
      "    Image Repo Tag:  docker.io/bluedata/sparkbase:2.2\n",
      "    Persist Dirs:\n",
      "      /usr\n",
      "      /opt\n",
      "      /var\n",
      "      /data\n",
      "    Cardinality:  0+\n",
      "    Config Package:\n",
      "      Package URL:   file:///opt/configscripts/appconfig-2.6.tgz\n",
      "    Id:              worker\n",
      "    Image Repo Tag:  docker.io/bluedata/sparkbase:2.2\n",
      "    Persist Dirs:\n",
      "      /usr\n",
      "      /opt\n",
      "      /var\n",
      "      /data\n",
      "    Cardinality:  0+\n",
      "    Config Package:\n",
      "      Package URL:   file:///opt/configscripts/appconfig-2.6.tgz\n",
      "    Id:              jupyter\n",
      "    Image Repo Tag:  docker.io/bluedata/jupyter:2.3\n",
      "    Persist Dirs:\n",
      "      /usr\n",
      "      /opt\n",
      "      /var\n",
      "      /data\n",
      "  Services:\n",
      "    Endpoint:\n",
      "      Is Dashboard:  false\n",
      "      Port:          22\n",
      "    Id:              ssh\n",
      "    Label:\n",
      "      Name:  SSH\n",
      "    Endpoint:\n",
      "      Is Dashboard:  true\n",
      "      Path:          /\n",
      "      Port:          8080\n",
      "      URL Scheme:    http\n",
      "    Id:              spark\n",
      "    Label:\n",
      "      Name:  Spark master\n",
      "    Endpoint:\n",
      "      Is Dashboard:  false\n",
      "      Port:          7077\n",
      "      URL Scheme:    spark\n",
      "    Id:              spark-master\n",
      "    Label:\n",
      "      Name:  Spark master\n",
      "    Endpoint:\n",
      "      Is Dashboard:  true\n",
      "      Path:          /\n",
      "      Port:          8081\n",
      "      URL Scheme:    http\n",
      "    Id:              spark-worker\n",
      "    Label:\n",
      "      Name:  Spark worker\n",
      "    Endpoint:\n",
      "      Is Dashboard:  true\n",
      "      Path:          /\n",
      "      Port:          8888\n",
      "      URL Scheme:    http\n",
      "    Id:              jupyter-nb\n",
      "    Label:\n",
      "      Name:          Jupyter Notebook\n",
      "  Systemd Required:  true\n",
      "  Version:           2.7\n",
      "Events:              <none>\n"
     ]
    }
   ],
   "source": [
    "kubectl describe kubedirectorapp spark221e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -2- Deploy Spark with Jupyter Notebook stateful application\n",
    "A configuration manifest YAML file is used to create KubeDirector virtual clusters that instantiate the defined KubeDirector App type. The configuration file is used to describe the attributes of a given KubeDirector App.\n",
    "\n",
    "We need to make sure the instance name of the KubeDirector Application is unique among your tenant. We also need to convert the application configuration manifest YAML file in a base64 encoded form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "apiVersion: \"kubedirector.hpe.com/v1beta1\"\n",
      "kind: \"KubeDirectorCluster\"\n",
      "metadata: \n",
      "  name: \"spark221e2-demouser\"\n",
      "  namespace: \"k8shacktenant\"\n",
      "spec: \n",
      "  app: \"spark221e2\"\n",
      "  appCatalog: \"local\"\n",
      "  roles: \n",
      "    - \n",
      "      id: \"controller\"\n",
      "      members: 1\n",
      "      resources: \n",
      "        requests: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "        limits: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "      storage: \n",
      "        size: \"10Gi\"\n",
      "    - \n",
      "      id: \"worker\"\n",
      "      members: 2\n",
      "      resources: \n",
      "        requests: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "        limits: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "      storage: \n",
      "        size: \"10Gi\"\n",
      "    - \n",
      "      id: \"jupyter\"\n",
      "      members: 1\n",
      "      resources: \n",
      "        requests: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "        limits: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "      storage: \n",
      "        size: \"10Gi\"\n"
     ]
    }
   ],
   "source": [
    "sed -i \"s/example/${username}/g\" $sparkApp\n",
    "cat $sparkApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration manifest specifies the application instance name, the KubeDirectorApp type, the application service roles and their number of nodes and compute size, as well as the storage size as Spark requires persistent storage to work. \n",
    "\n",
    "*Note: In this deployment, the Spark KubeDirectorApp variant used here is a distributed implementation of Spark cluster where the master (Spark driver) and worker (Spark executor) services run on different cluster nodes (controller and workers). A separate Jupyter node (Id: jupyter) is used as interactive client to execute programs on Spark cluster.*\n",
    "\n",
    "Let's deploy it now using the REST API call below. The REST API call requires the **kubectl** operation type (create or apply) and the application manifest in a base64 encoded form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubedirectorcluster.kubedirector.hpe.com/spark221e2-demouser created"
     ]
    }
   ],
   "source": [
    "mysparkapp=$(base64 $sparkApp)\n",
    "#echo $mysparkapp\n",
    "curl -k -s --request POST \"https://${controller_endpoint}/api/v2/k8scluster/${k8sClusterId}/kubectl\" \\\n",
    "--header \"X-BDS-SESSION: $sessionlocation\" \\\n",
    "--header 'Accept: application/json' \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data-raw '{\n",
    "\"data\": \"'\"$mysparkapp\"'\",\n",
    "\"op\": \"apply\"\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a minute or so, you should get the message *kubedirectorcluster/Your-instance-name created*.  \n",
    "\n",
    "Once you get this message, go to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -3- Inspect the deployed KubeDirector application virtual cluster \n",
    "Your application virtual cluster will be represented in the Kubernetes cluster by a resource of type **KubeDirectorCluster**, with the name that was indicated inside the YAML file used to create it. **A kubeDirectorCluster resource is an instantiation of a KubeDirector App**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                  AGE\n",
      "spark221e2-demouser   6s\n"
     ]
    }
   ],
   "source": [
    "clusterName=\"spark221e2-${username}\"\n",
    "kubectl get kubedirectorcluster $clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the instance of the KubeDirector Application, you can use kubectl command below to observe its status and the standard Kubernetes resources that make up the application virtual cluster (statefulsets, pods, services, persistent volume claim if any) and any events logged against it.\n",
    "\n",
    "The virtual cluster status indicates its overall \"state\" (top-level property of the status object). It should have a value of **\"configured\"**. The first time a virtual cluster of a given KubeDirector App type is created, it may take some minutes to reach \"configured\" state, as the relevant Docker image must be downloaded and imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         spark221e2-demouser\n",
      "Namespace:    k8shacktenant\n",
      "Labels:       <none>\n",
      "Annotations:  kubectl.kubernetes.io/last-applied-configuration:\n",
      "                {\"apiVersion\":\"kubedirector.hpe.com/v1beta1\",\"kind\":\"KubeDirectorCluster\",\"metadata\":{\"annotations\":{},\"name\":\"spark221e2-demouser\",\"names...\n",
      "API Version:  kubedirector.hpe.com/v1beta1\n",
      "Kind:         KubeDirectorCluster\n",
      "Metadata:\n",
      "  Creation Timestamp:  2020-04-15T22:30:57Z\n",
      "  Finalizers:\n",
      "    kubedirector.hpe.com/cleanup\n",
      "  Generation:        1\n",
      "  Resource Version:  5655053\n",
      "  Self Link:         /apis/kubedirector.hpe.com/v1beta1/namespaces/k8shacktenant/kubedirectorclusters/spark221e2-demouser\n",
      "  UID:               f6060712-d478-4976-ad7f-400b06be8afd\n",
      "Spec:\n",
      "  App:          spark221e2\n",
      "  App Catalog:  local\n",
      "  Roles:\n",
      "    Id:       controller\n",
      "    Members:  1\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     2\n",
      "        Memory:  4Gi\n",
      "      Requests:\n",
      "        Cpu:     2\n",
      "        Memory:  4Gi\n",
      "    Storage:\n",
      "      Size:                10Gi\n",
      "      Storage Class Name:  default\n",
      "    Id:                    worker\n",
      "    Members:               2\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     2\n",
      "        Memory:  4Gi\n",
      "      Requests:\n",
      "        Cpu:     2\n",
      "        Memory:  4Gi\n",
      "    Storage:\n",
      "      Size:                10Gi\n",
      "      Storage Class Name:  default\n",
      "    Id:                    jupyter\n",
      "    Members:               1\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     2\n",
      "        Memory:  4Gi\n",
      "      Requests:\n",
      "        Cpu:     2\n",
      "        Memory:  4Gi\n",
      "    Storage:\n",
      "      Size:                10Gi\n",
      "      Storage Class Name:  default\n",
      "  Service Type:            NodePort\n",
      "Status:\n",
      "  Cluster Service:  kdhs-lbjmt\n",
      "  Generation UID:   1359c42c-2efd-4c7e-8d32-e92ec051be22\n",
      "  Last Node ID:     4\n",
      "  Member State Rollup:\n",
      "    Config Errors:         false\n",
      "    Members Down:          false\n",
      "    Members Initializing:  false\n",
      "    Members Restarting:    false\n",
      "    Members Waiting:       false\n",
      "    Membership Changing:   false\n",
      "  Roles:\n",
      "    Id:  controller\n",
      "    Members:\n",
      "      Node ID:  1\n",
      "      Pod:      kdss-j2v6x-0\n",
      "      Pvc:      p-kdss-j2v6x-0\n",
      "      Service:  s-kdss-j2v6x-0\n",
      "      State:    configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  1\n",
      "        Last Configured Container:    docker://af444c265fe894369f842f940d5b5c53a3ce61d51c29905a3713b0a0d528b947\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        1\n",
      "    Stateful Set:                     kdss-j2v6x\n",
      "    Id:                               worker\n",
      "    Members:\n",
      "      Node ID:  2\n",
      "      Pod:      kdss-7dtqk-0\n",
      "      Pvc:      p-kdss-7dtqk-0\n",
      "      Service:  s-kdss-7dtqk-0\n",
      "      State:    configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  1\n",
      "        Last Configured Container:    docker://7e40ab6da008147f8935eda45c50ae0c3bbac3faf36e892afaf1aabbef7ed52d\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        1\n",
      "      Node ID:                        3\n",
      "      Pod:                            kdss-7dtqk-1\n",
      "      Pvc:                            p-kdss-7dtqk-1\n",
      "      Service:                        s-kdss-7dtqk-1\n",
      "      State:                          configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  1\n",
      "        Last Configured Container:    docker://0e4a2c830dea5b5e67cb964206ea8514ddced7d784c93d461f00b6fc96ceeb3c\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        1\n",
      "    Stateful Set:                     kdss-7dtqk\n",
      "    Id:                               jupyter\n",
      "    Members:\n",
      "      Node ID:  4\n",
      "      Pod:      kdss-mwkh4-0\n",
      "      Pvc:      p-kdss-mwkh4-0\n",
      "      Service:  s-kdss-mwkh4-0\n",
      "      State:    configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  1\n",
      "        Last Configured Container:    docker://546fb57fc9ddd33d0a3d995259f33b6d776a5a4474c8a9788f1e3a367a621171\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        1\n",
      "    Stateful Set:                     kdss-mwkh4\n",
      "  Spec Generation To Process:         1\n",
      "  State:                              configured\n",
      "Events:\n",
      "  Type    Reason   Age                    From          Message\n",
      "  ----    ------   ----                   ----          -------\n",
      "  Normal  Cluster  31m                    kubedirector  new\n",
      "  Normal  Role     31m                    kubedirector  creating role{controller}\n",
      "  Normal  Role     31m                    kubedirector  creating role{worker}\n",
      "  Normal  Role     31m                    kubedirector  creating role{jupyter}\n",
      "  Normal  Role     31m                    kubedirector  changing replicas count for role{controller}: 0 -> 1\n",
      "  Normal  Role     31m                    kubedirector  changing replicas count for role{worker}: 0 -> 2\n",
      "  Normal  Role     31m                    kubedirector  changing replicas count for role{jupyter}: 0 -> 1\n",
      "  Normal  Member   8m57s (x4 over 9m41s)  kubedirector  initial config ongoing for member{kdss-j2v6x-0} in role{controller}\n",
      "  Normal  Member   8m27s (x6 over 9m19s)  kubedirector  initial config ongoing for member{kdss-7dtqk-0} in role{worker}\n",
      "  Normal  Member   8m27s                  kubedirector  initial config done for member{kdss-j2v6x-0} in role{controller}\n",
      "  Normal  Member   7m57s                  kubedirector  initial config done for member{kdss-7dtqk-0} in role{worker}\n",
      "  Normal  Member   7m56s (x7 over 8m58s)  kubedirector  initial config ongoing for member{kdss-7dtqk-1} in role{worker}\n",
      "  Normal  Member   7m26s                  kubedirector  initial config done for member{kdss-7dtqk-1} in role{worker}\n",
      "  Normal  Member   6m26s (x4 over 7m5s)   kubedirector  initial config ongoing for member{kdss-mwkh4-0} in role{jupyter}\n"
     ]
    }
   ],
   "source": [
    "kubectl describe kubedirectorcluster $clusterName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               READY   STATUS    RESTARTS   AGE\n",
      "pod/kdss-7dtqk-0   1/1     Running   0          31m\n",
      "pod/kdss-7dtqk-1   1/1     Running   0          31m\n",
      "pod/kdss-j2v6x-0   1/1     Running   0          31m\n",
      "pod/kdss-mwkh4-0   1/1     Running   0          31m\n",
      "\n",
      "NAME                     TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                                                     AGE\n",
      "service/kdhs-lbjmt       ClusterIP   None           <none>        8888/TCP                                                    31m\n",
      "service/s-kdss-7dtqk-0   NodePort    10.96.141.31   <none>        22:32677/TCP,8081:31223/TCP                                 31m\n",
      "service/s-kdss-7dtqk-1   NodePort    10.96.44.156   <none>        22:32143/TCP,8081:30019/TCP                                 31m\n",
      "service/s-kdss-j2v6x-0   NodePort    10.96.215.65   <none>        22:30358/TCP,8080:31430/TCP,7077:31358/TCP,8081:31160/TCP   31m\n",
      "service/s-kdss-mwkh4-0   NodePort    10.96.5.87     <none>        22:30390/TCP,8888:30227/TCP                                 31m\n",
      "\n",
      "NAME                          READY   AGE\n",
      "statefulset.apps/kdss-7dtqk   2/2     31m\n",
      "statefulset.apps/kdss-j2v6x   1/1     31m\n",
      "statefulset.apps/kdss-mwkh4   1/1     31m\n",
      "NAME             STATUS   VOLUME                                         CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
      "p-kdss-7dtqk-0   Bound    mapr-pv-84ebfd58-e33e-4535-8856-6ef3b54f84a5   10Gi       RWO            default        31m\n",
      "p-kdss-7dtqk-1   Bound    mapr-pv-898d2f58-f516-40ef-bc37-7bd418888f78   10Gi       RWO            default        31m\n",
      "p-kdss-j2v6x-0   Bound    mapr-pv-c635bfa2-b773-430b-aabf-ecc3e0a8bfb5   10Gi       RWO            default        31m\n",
      "p-kdss-mwkh4-0   Bound    mapr-pv-49b9ffb5-b14a-4703-95a3-95b4695eb4f7   10Gi       RWO            default        31m\n"
     ]
    }
   ],
   "source": [
    "kubectl get all -l kubedirector.hpe.com/kdcluster=$clusterName\n",
    "\n",
    "kubectl get pvc -l kubedirector.hpe.com/kdcluster=$clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your KubeDirector application virtual cluster is made up of a **StatefulSet** per role (Spark controller, Spark workers, and jupyter), a **POD** (a cluster node) and a **NodePort Service** per service role member,  a **headless service** for the application cluster and a **Persistent Volume Claim (pvc)** per POD that requested persistent storage.  \n",
    "\n",
    "* The ClusterIP service is the headless service required by a Kubernetes StatefulSet to work. It maintains a stable POD network identity (i.e.: persistence of the hostname of the PODs across PODs rescheduling).\n",
    "* The NodePort service exposes an application service outside the Kubernetes cluster. \n",
    "HPE Container Platform automatically maps the NodePort Service endpoint to the HPE Container Platform gateway (proxy) host.\n",
    "* HPE Container Platform defines HPE Data Fabric (aka MapR Data Platform) as **default** Kubernetes StorageClass for the Kubernetes Clusters managed by HPE Container Platform. HPE CP uses MapR Container Storage Interface (CSI) storage plugin to expose the HPE Data Fabric as storage provider to the Kubernetes containerized workloads (i.e.: PODs) that request persistent storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -4- Get the application service endpoints\n",
    "To get a report on all services related to a specific virtual cluster, you can use a form of \"kubectl describe\" that matches against a value of the **kubedirector.hpe.com/kdcluster=YourClusterApplicationName** label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your application virtual cluster service endpoint (Jupyter) is: https://gateway1.etc.fr.comm.hpecorp.net:10009\n",
      "Your application virtual cluster service endpoint (Spark Master) is: https://gateway1.etc.fr.comm.hpecorp.net:10006\n",
      "Your application virtual cluster service endpoint (Spark Worker) is: https://gateway1.etc.fr.comm.hpecorp.net:10007 gateway1.etc.fr.comm.hpecorp.net:10008 gateway1.etc.fr.comm.hpecorp.net:10011\n"
     ]
    }
   ],
   "source": [
    "#Jupyter Notebook service\n",
    "sparkappJupyterURL=$(kubectl describe service -l  kubedirector.hpe.com/kdcluster=${clusterName} | grep gateway1 | grep 8888 | awk '{print $2}')\n",
    "mysparkapp_Jupyter_endpoint=\"https://${sparkappJupyterURL}\"\n",
    "\n",
    "#Spark cluster Master service Web UI:\n",
    "sparkappSparkURL=$(kubectl describe service -l  kubedirector.hpe.com/kdcluster=${clusterName} | grep gateway1 | grep 8080 | awk '{print $2}')\n",
    "mysparkapp_Spark_endpoint=\"https://${sparkappSparkURL}\"\n",
    "\n",
    "#Spark cluster Worker service Web UI:\n",
    "sparkappSparkWorkerURL=$(kubectl describe service -l  kubedirector.hpe.com/kdcluster=${clusterName} | grep gateway1 | grep 8081 | awk '{print $2}')\n",
    "mysparkapp_SparkWorker_endpoint=\"https://${sparkappSparkWorkerURL}\"\n",
    "\n",
    "echo \"Your application virtual cluster service endpoint (Jupyter) is: \"$mysparkapp_Jupyter_endpoint\n",
    "echo \"Your application virtual cluster service endpoint (Spark Master) is: \"$mysparkapp_Spark_endpoint\n",
    "echo \"Your application virtual cluster service endpoint (Spark Worker) is: \"$mysparkapp_SparkWorker_endpoint\n",
    "\n",
    "#kubectl describe service -l  kubedirector.hpe.com/kdcluster=${clusterName}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access to application services running in containers is proxied via the gateway host and a port number greater than 10000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -5- Check the Spark cluster is running and Jupyter application service is responding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Master Web UI service response:\n",
      "HTTP/1.1 200 OK\n"
     ]
    }
   ],
   "source": [
    "echo \"Spark Master Web UI service response:\"\n",
    "curl -k -L -s -i \"${mysparkapp_Spark_endpoint}\" | grep \"HTTP/1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"Spark Worker Web UI service response:\"\n",
    "curl -k -L -s -i \"${mysparkapp_SparkWorker_endpoint}\" | grep \"HTTP/1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter service response:\n",
      "HTTP/1.1 302 Found\n",
      "HTTP/1.1 302 Found\n",
      "HTTP/1.1 200 OK\n"
     ]
    }
   ],
   "source": [
    "echo \"Jupyter service response:\"\n",
    "curl -k -L -s -i \"${mysparkapp_Jupyter_endpoint}\" | grep \"HTTP/1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -6- Connect to your application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can connect to your Spark framework web UI dashboard and Jupyter Notebook and start your real time data processing.\n",
    "\n",
    "Open a new tab in your browser, and connect to the service endpoint: https://77.158.163.130:YourPortNumber\n",
    "where 77.158.163.130 is the NAT IP address of the HPE CP proxy gateway, port number is the port you get for your service endpoint. \n",
    "\n",
    "**Note:** In the first release of HPE Container Platform, the deployed instances of KubeDirectorApp containers do not have any login-capable accounts. Ask your administrator for Jupyter Notebook password.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spark Master Web UI:**\n",
    "\n",
    "![Spark Cluster Master Web UI](Pictures/Spark-Cluster-Master-Web-UI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spark Worker Web UI:** \n",
    "\n",
    "![Spark Cluster Worker Web UI](Pictures/Spark-Cluster-Worker-Web-UI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter Notebook:** \n",
    "\n",
    "![Spark client - Jupyter Notebook](Pictures/Spark-Jupyter-Notebook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -7- Resizing the KubeDirector App cluster instance\n",
    "To increase or decrease the number of members in a role, you would just have to edit the configuration YAML file and use the kubectl apply REST API call to apply the changes. The KubeDirector operator will manage the application cluster expansion or shrinkage for you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -8- Go through some cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First delete the kubedirector application cluster instance using the REST API (POST) call below. The REST API call requires the **kubectl** operation type (delete) and the application manifest in a base64 encoded form.\n",
    "Deleting the KubeDirectorCluster resource will automatically delete all resources (the pods, services, pvc, statefulset) that compose the KubeDirector application virtual cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubedirectorcluster.kubedirector.hpe.com \"spark221e2-demouser\" deleted"
     ]
    }
   ],
   "source": [
    "curl -k -s --request POST \"https://${controller_endpoint}/api/v2/k8scluster/${k8sClusterId}/kubectl\" \\\n",
    "--header \"X-BDS-SESSION: $sessionlocation\" \\\n",
    "--header 'Accept: application/json' \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data-raw '{\n",
    "\"data\": \"'\"$mysparkapp\"'\",\n",
    "\"op\": \"delete\"\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Although session have a time to live (TTL) of 24 hours, it is best practice in REST API programming to cleanup and delete those sessions when done. We can use a DELETE /api/v2/session/SessionId to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 204 No Content\n",
      "Access-Control-Allow-Origin: *\n",
      "Content-Length: 0\n",
      "Content-Type: text/plain\n",
      "Date: Wed, 15 Apr 2020 23:11:14 GMT\n",
      "Server: BlueData EPIC 5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "curl -k -i -s --request DELETE \"https://${controller_endpoint}/api/v2/session/${SessionId}\" \\\n",
    "--header \"X-BDS-SESSION: $sessionlocation\" \\\n",
    "--header 'Accept: application/json' \\\n",
    "--header 'Content-Type: application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status *204 No Content* means the session object has been deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, reset your applications YAML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: apps/v1\n",
      "kind: Deployment\n",
      "metadata:\n",
      "  name: hello-world-example\n",
      "spec:\n",
      "  selector:\n",
      "    matchLabels:\n",
      "      run: load-balancer-example\n",
      "  replicas: 2\n",
      "  template:\n",
      "    metadata:\n",
      "      labels:\n",
      "        run: load-balancer-example\n",
      "    spec:\n",
      "      containers:\n",
      "        - name: hello-world-example\n",
      "          image: gcr.io/google-samples/node-hello:1.0\n",
      "          ports:\n",
      "            - containerPort: 8080\n",
      "              protocol: TCP\n",
      "---\n",
      "apiVersion: v1\n",
      "kind: Service\n",
      "metadata:\n",
      "  name: hello-world-service-example\n",
      "spec:\n",
      "  selector:\n",
      "    run: load-balancer-example\n",
      "  ports:\n",
      "  - name: http-hello\n",
      "    protocol: TCP\n",
      "    port: 8080\n",
      "    targetPort: 8080\n",
      "  type: NodePort\n",
      "---\n",
      "apiVersion: \"kubedirector.hpe.com/v1beta1\"\n",
      "kind: \"KubeDirectorCluster\"\n",
      "metadata: \n",
      "  name: \"spark221e2-example\"\n",
      "  namespace: \"k8shacktenant\"\n",
      "spec: \n",
      "  app: \"spark221e2\"\n",
      "  appCatalog: \"local\"\n",
      "  roles: \n",
      "    - \n",
      "      id: \"controller\"\n",
      "      members: 1\n",
      "      resources: \n",
      "        requests: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "        limits: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "      storage: \n",
      "        size: \"10Gi\"\n",
      "    - \n",
      "      id: \"worker\"\n",
      "      members: 2\n",
      "      resources: \n",
      "        requests: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "        limits: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "      storage: \n",
      "        size: \"10Gi\"\n",
      "    - \n",
      "      id: \"jupyter\"\n",
      "      members: 1\n",
      "      resources: \n",
      "        requests: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "        limits: \n",
      "          memory: \"4Gi\"\n",
      "          cpu: \"2\"\n",
      "      storage: \n",
      "        size: \"10Gi\"\n"
     ]
    }
   ],
   "source": [
    "#reset the application deployment name in the YAML file\n",
    "sed -i \"s/${username}/example/g\" $helloWorldApp\n",
    "sed -i \"s/${username}/example/g\" $sparkApp\n",
    "cat $helloWorldApp\n",
    "cat $sparkApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how **Kubernetes tenant** users can deploy, using REST API, both cloud-native stateless, microservices applications, and non-cloud-native distributed stateful AI/analytics KubeDirector applications on Kubernetes clusters managed by HPE Container Platform. You also used the standard Kubernetes command line (kubectl) as well as the HPE CP plugin to establish HPECP-authenticated kubectl requests in the context of your tenant user account. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
