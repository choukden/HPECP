{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline with KubeDirector - Lab 2\n",
    "## Deploy a local Jupyter Notebook cluster to interact with a tenant-shared training cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lab workflow:**\n",
    "\n",
    "In this lab:\n",
    "\n",
    "1. As tenant user, you will first create a local (lightweight) Jupyter Notebook application KubeDirector cluster to develop your model. You will attach your Jupyter Notebook cluster to a remote tenant-shared training cluster to train your model. The shared training cluster **training-engine-shared** includes the open source ML toolkits, libraries and frameworks for developing and training models. It has been already deployed by the tenant administrator for your tenant. The shared training cluster will allow you to train your model faster using more compute and memory resources than your local lightweight Jupyter Notebook cluster.\n",
    "\n",
    "2. You will then access your local Jupyter Notebook web UI via the gateway network service port to train your model to the remote tenant-shared training cluster. \n",
    "\n",
    "**Recommended blog reading:**\n",
    "\n",
    "* [Building Dynamic Machine Learning Pipelines with KubeDirector](https://developer.hpe.com/blog/building-dynamic-machine-learning-pipelines-with-kubedirector)\n",
    "\n",
    "**Definitions:**\n",
    "\n",
    "- *KubeDirector:* also known as Kubernetes Director. KubeDirector is an **open-source** project initiated and led by HPE that addresses stateful scaleout application deployment in standard Kubernetes clusters with a focus on non-cloud native stateful analytics workloads (AI/ML, data processing and Big Data apps). These applications generally refer to as a distributed, single-node or multi-node application **virtual cluster** where each application virtual cluster node runs as **a container** in the Kubernetes cluster.\n",
    "\n",
    "- *Training:* Input datasets are processed to create Machine Learning Model. Data Scientists can use local Jupyter Notebook to build their models and train their models. They can also interact with remote larger capacity training cluster to train their models faster.\n",
    "\n",
    "- *Cloud native application:* Also known as the [12-Factor app](https://www.mirantis.com/blog/how-do-you-build-12-factor-apps-using-kubernetes/), a modern application that leverages microservices architecture with loosely coupled services. The microservice architectural style is an approach to developing a single application as a suite of small independently deployed services.\n",
    "\n",
    "- *Non-cloud native application:* a multi-tier application with tightly coupled and interdependent services. \n",
    "\n",
    "- *Stateless application:* A stateless application is an application which does not require persistence of data nor an application state.\n",
    "\n",
    "- *Stateful application:* A stateful application typically requires persistence of certain mountpoints across application cluster nodes rescheduling, restarts, upgrades, rollbacks. A stateful application can also need persistence of network identity (i.e.: hostname). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Download the python code files to your PC/laptop:**\n",
    "\n",
    "From the left side panel, navigate to **Code/NYCTaxi** folder and download the files:\n",
    "- _**3-WKSHP-K8s-ML-Pipeline-Model-Training.ipynb**_\n",
    "- _**XGB_Scoring.py**_\n",
    "- _**XGB_Scoringv2.py**_\n",
    "- _**ML-Workflow.jpg**_\n",
    "\n",
    "Double-click on the folder **Code**, then folder **NYCTaxi**. Right-click on each code file and choose **Download**.\n",
    "\n",
    "You will need these files in the next lab.\n",
    "\n",
    "You can click the ellipsis **(...)** to go back to the root of your repository in JupyterHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the environment:\n",
    "\n",
    "Let's first define the environment variables needed to execute this lab part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your studentId is: student74\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# environment variables to be verified by the student\n",
    "#\n",
    "studentId=\"student{{ STDID }}\" # your Jupyter Notebook student Identifier (i.e.: student<xx>)\n",
    "\n",
    "studentId=\"student74\"\n",
    "\n",
    "# fixed environment variables setup by the HPE ECP lab administrator - Please DO NOT MODIFY!!\n",
    "\n",
    "gateway_host=\"{{ HPEECPGWNAME }}\"\n",
    "Internet_access=\"{{ JPHOSTEXT }}\"\n",
    "\n",
    "gateway_host=\"hpecpgw1.hp.local\"\n",
    "Internet_access=\"notebooks2.hpedev.io\"\n",
    "\n",
    "JupyterNotebookApp=\"cr-cluster-jupyter-notebook.yaml\" # the Jupyter Notebook KD App manifest you will deploy to build your model\n",
    "DeploymentEngineApp=\"cr-cluster-endpoint-wrapper.yaml\" # the Deployment engine KD App manifest you will deploy to query your model for answers\n",
    "\n",
    "echo \"Your studentId is: \"$studentId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the registered KubeDirector Applications:\n",
    "You can get the list of KubeDirector Applications (kdapp) registered with the Kubernetes cluster for your Tenant using the following kubectl command. A KubeDirector Application is a _template_ for the application. It describes an application's **metadata** (service roles, Docker images, configuration packages, services ports, persistent storage).\n",
    "In this workshop, you will be using the following KubeDirector Applications: _jupyter-notebook-v1_ to build your model and _deployment-engine_ app to deploy your trained model and serve prediction queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     AGE\n",
      "centos8x                 22h\n",
      "deployment-engine        22h\n",
      "jupyter-notebook         22h\n",
      "jupyter-notebook-v1      22h\n",
      "spark245                 22h\n",
      "tensorflow-gpu-jupyter   22h\n",
      "training-engine          22h\n",
      "ubuntu18x                22h\n"
     ]
    }
   ],
   "source": [
    "kubectl get kdapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the existing KubeDirector Training cluster deployed on the Kubernetes cluster for your tenant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     AGE\n",
      "training-engine-shared   22h\n"
     ]
    }
   ],
   "source": [
    "kubectl get kdcluster training-engine-shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying your local Jupyter Notebook cluster with Connection to the Training cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy an instance of the Jupyter Notebook KubeDirector application:\n",
    "You will deploy an instance of the **jupyter-notebook** KubeDirector application (kdapp) with the Training cluster _Connection_ by creating a KubeDirector virtual cluster (kdcluster). A kdcluster identifies the desired kdapp and specifies runtime configuration parameters, such as the size and resource requirements of the virtual cluster. \n",
    "\n",
    "> **Note:** _The Jupyter-Notebook kdapp includes the open source Machine learning toolkits, software libraries and frameworks for developing and training models such as TensorFlow, scikit-learn, keras, XGBoost, matplotlib, Jupyter Notebook, Numpy, Scipy, Pandas..._\n",
    "\n",
    "Like any other containerized application deployment on Kubernetes, the K8s API call requires the kubectl operation type (create or apply) and the application manifest (a YAML file that describes the attributes of the application).  \n",
    "\n",
    "As you are all sharing the same tenant context and Kubernetes cluster resources, let's make sure your application deployment name will be unique among the tenant users. Here we replace the string \"example\" with your \"studentId\" in the application manifest file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"kubedirector.hpe.com/v1beta1\"\n",
      "kind: \"KubeDirectorCluster\"\n",
      "metadata:\n",
      "  name: \"jupyter-notebook-student74\"\n",
      "spec:\n",
      "  app: \"jupyter-notebook-v1\"\n",
      "  appCatalog: \"local\"\n",
      "  connections: \n",
      "    #secrets: \n",
      "      #- \n",
      "        #\"some secrets\"\n",
      "    #configmaps: \n",
      "      #- \n",
      "        #\"some configmaps\"\n",
      "    clusters: \n",
      "      - \"training-engine-shared\"\n",
      "        #\"some clusters\"\n",
      "  roles:\n",
      "  - id: controller\n",
      "    resources:\n",
      "      requests:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "      limits:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n"
     ]
    }
   ],
   "source": [
    "sed -i \"s/example/${studentId}/g\" $JupyterNotebookApp\n",
    "cat $JupyterNotebookApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** _one of the most interesting parts of the kdcluster spec is the **Connections** stanza (a related group of attributes), which identifies other resources of interest to that kdcluster. Here, you simply connect your local Jupyter Notebook cluster to the tenant-shared training cluster **training-engine-shared** already deployed by the tenant administrator._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubedirectorcluster.kubedirector.hpe.com/jupyter-notebook-student74 created\n"
     ]
    }
   ],
   "source": [
    "kubectl apply -f $JupyterNotebookApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds, you should get the response message to your K8s API request: *kubedirectorcluster/Your-instance-name created*.  \n",
    "\n",
    "In the next steps, you will use kubectl commands in the context of your tenant user account and get the Notebook service endpoint with token-based authorization to connect to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the deployed KubeDirector application instance: \n",
    "Your application will be represented in the Kubernetes cluster by a custom resource of type **KubeDirectorCluster (kdcluster)**, with the name that was indicated inside the YAML file used to create it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                         AGE\n",
      "jupyter-notebook-student74   5s\n"
     ]
    }
   ],
   "source": [
    "clusterName=\"jupyter-notebook-${studentId}\"\n",
    "kubectl get kdcluster $clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the instance of the KubeDirector Application, you can use the `kubectl describe kdcluster` command below to observe its status and the standard Kubernetes resources that compose the application virtual cluster (statefulsets, pods, services, persistent volume claim if any), as well as any events logged against it.\n",
    "\n",
    "The virtual cluster status indicates its overall \"state\" (top-level property of the status object). It should have a value of **\"configured\"**. \n",
    "\n",
    "> **Note:** _The first time a virtual cluster of a given KubeDirector Application type is created, it may take some minutes to reach its **\"configured\"** state, as the relevant Docker image must be downloaded and imported._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat the command below until the kdcluster is in state \"configured\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         jupyter-notebook-student74\n",
      "Namespace:    k8smltenant\n",
      "Labels:       <none>\n",
      "Annotations:  <none>\n",
      "API Version:  kubedirector.hpe.com/v1beta1\n",
      "Kind:         KubeDirectorCluster\n",
      "Metadata:\n",
      "  Creation Timestamp:  2020-12-16T18:25:11Z\n",
      "  Finalizers:\n",
      "    kubedirector.hpe.com/cleanup\n",
      "  Generation:        1\n",
      "  Resource Version:  307974\n",
      "  Self Link:         /apis/kubedirector.hpe.com/v1beta1/namespaces/k8smltenant/kubedirectorclusters/jupyter-notebook-student74\n",
      "  UID:               7afed7a4-454d-48f4-8ada-2511dcc4f1ae\n",
      "Spec:\n",
      "  App:          jupyter-notebook-v1\n",
      "  App Catalog:  local\n",
      "  Connections:\n",
      "    Clusters:\n",
      "      training-engine-shared\n",
      "  Naming Scheme:  UID\n",
      "  Roles:\n",
      "    Id:       controller\n",
      "    Members:  1\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "      Requests:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "  Service Type:  NodePort\n",
      "Status:\n",
      "  Cluster Service:       kdhs-7hkcl\n",
      "  Generation UID:        bf08b83b-512a-42ef-9cad-9ff750e0a90b\n",
      "  Last Connection Hash:  4460c69178ccca0aad5466f0835041e6\n",
      "  Last Node ID:          1\n",
      "  Member State Rollup:\n",
      "    Config Errors:         false\n",
      "    Members Down:          false\n",
      "    Members Initializing:  false\n",
      "    Members Restarting:    false\n",
      "    Members Waiting:       false\n",
      "    Membership Changing:   false\n",
      "  Roles:\n",
      "    Id:  controller\n",
      "    Members:\n",
      "      Auth Token:  32be7733e1ff90be0168b9fc29d64ecf\n",
      "      Node ID:     1\n",
      "      Pod:         kdss-x7fx4-0\n",
      "      Service:     s-kdss-x7fx4-0\n",
      "      State:       configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  1\n",
      "        Last Configured Container:    docker://9bc9fd2aef3f8eb204872502872d8f0ee22ba396bd26c7fe96fcd5e21ad1dc51\n",
      "        Last Connection Version:      0\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        1\n",
      "    Stateful Set:                     kdss-x7fx4\n",
      "  Spec Generation To Process:         1\n",
      "  State:                              configured\n",
      "Events:\n",
      "  Type    Reason   Age   From          Message\n",
      "  ----    ------   ----  ----          -------\n",
      "  Normal  Cluster  98s   kubedirector  new\n",
      "  Normal  Role     98s   kubedirector  creating role{controller}\n",
      "  Normal  Cluster  98s   kubedirector  Annotation initialized to 1\n",
      "  Normal  Role     98s   kubedirector  changing replicas count for role{controller}: 0 -> 1\n",
      "  Normal  Role     97s   kubedirector  waiting for replicas count for role{controller}: 0 -> 1\n",
      "  Normal  Member   48s   kubedirector  initial config ongoing for member{kdss-x7fx4-0} in role{controller}\n",
      "  Normal  Member   47s   kubedirector  initial config done for member{kdss-x7fx4-0} in role{controller}\n",
      "  Normal  Cluster  47s   kubedirector  stable\n"
     ]
    }
   ],
   "source": [
    "kubectl describe kdcluster $clusterName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               READY   STATUS    RESTARTS   AGE\n",
      "pod/kdss-x7fx4-0   1/1     Running   0          104s\n",
      "\n",
      "NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                       AGE\n",
      "service/kdhs-7hkcl       ClusterIP   None            <none>        8888/TCP                      104s\n",
      "service/s-kdss-x7fx4-0   NodePort    10.106.117.62   <none>        22:32013/TCP,8888:32674/TCP   104s\n",
      "\n",
      "NAME                          READY   AGE\n",
      "statefulset.apps/kdss-x7fx4   1/1     105s\n"
     ]
    }
   ],
   "source": [
    "kubectl get all -l kubedirector.hpe.com/kdcluster=$clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your instance of the KubeDirector Application virtual cluster is made up of a **StatefulSet**, a **POD** (a cluster node) and a **NodePort Service** per service role member (Controller), and a **headless service** for the application cluster.   \n",
    "\n",
    "* The ClusterIP service is the headless service required by a Kubernetes StatefulSet to work. It maintains a stable POD network identity (i.e.: persistence of the hostname of the PODs across PODs rescheduling).\n",
    "* The NodePort service exposes the Notebook application service with token-based authorization outside the Kubernetes cluster. \n",
    "\n",
    "HPE Ezmeral Container Platform automatically maps the NodePort Service endpoints to the HPE Ezmeral Container Platform gateway (haproxy) host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the gateway mapped application service endpoint and the Authentication token to connect to your local Jupyter Notebook:\n",
    "To get a report on all services related to a specific virtual KubeDirector cluster, you can use a form of **kubectl describe** that matches against a value of the **kubedirector.hpe.com/kdcluster=YourClusterApplicationName** label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your application service endpoint re-mapped port is: 10146\n",
      "Your Jupyter Notebook service endpoint URL is: https://notebooks2.hpedev.io:10146\n",
      "Your Jupyter Notebook service authentication token is: 32be7733e1ff90be0168b9fc29d64ecf\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Getting the service endpoint URL:\n",
    "#\n",
    "JupyterAppURL=$(kubectl describe service -l  kubedirector.hpe.com/kdcluster=${clusterName} | grep gateway/8888 | awk '{print $2}')\n",
    "JupyterAppPort=$(echo $JupyterAppURL | cut -d':' -f 2) # extract the gateway re-mapped port value.\n",
    "myJupyterApp_endpoint=\"https://$gateway_host:$JupyterAppPort\"\n",
    "echo \"Your application service endpoint re-mapped port is: \"$JupyterAppPort\n",
    "#echo \"Your Intranet application service endpoint is: \"$myJupyterApp_endpoint\n",
    "echo \"Your Jupyter Notebook service endpoint URL is: https://\"$Internet_access:$JupyterAppPort\n",
    "#\n",
    "# Getting the auth-token:\n",
    "#\n",
    "JupyterAuthToken=$(kubectl describe service -l  kubedirector.hpe.com/kdcluster=${clusterName} | grep kd-auth-token | awk '{print $2}')\n",
    "echo \"Your Jupyter Notebook service authentication token is: \"$JupyterAuthToken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your local Jupyter Notebook web UI and Upload code files\n",
    "Click the service endpoint URL above to connect to your Jupyter Notebook server.\n",
    "This opens a Jupyter Notebook login screen in a new browser tab. Login with the authentication token above (copy/paste the token value above) and follow instructions below to upload the code files (downloaded at the beginning of this lab part) to your local Jupyter Notebook server.\n",
    "\n",
    "![Jupyter-Notebook-Login](Pictures/Jupyter-Notebook-Login.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on **Upload** button on the top right of your local Jupyter Notebook server.\n",
    "\n",
    "![Jupyter-Notebook-Upload](Pictures/Jupyter-Notebook-Upload.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the Lab 3 python code file **3-WKSHP-K8s-ML-Pipeline-Model-Training.ipynb** from your laptop downloaded at the beginning of this lab, and click on **Upload** button as shown here:\n",
    "\n",
    "![Lab3 code upload](Pictures/Jupyter-Notebook-Upload-file.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same steps to upload the files **XGB_Scoring.py**, **XGB_Scoringv2.py** and **ML-Workflow.jpg** from your laptop downloaded at the beginning of this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">Now, from your local Jupyter Notebook, open the notebook **3-WKSHP-K8s-ML-Pipeline-Model-Training.ipynb** and follow the instructions from the notebook to build, train and test the model.</font>\n",
    "\n",
    "Once your model is trained and saved to a file, follow the instructions in Lab 4 to deploy you trained model:\n",
    "\n",
    "* [Lab 4 Model Registry and Deployment](4-WKSHP-K8s-ML-Pipeline-Register-Model-Deployment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we have shown you how you, **as tenant user**, can deploy a local Jupyter Notebook virtual cluster and attach it to a shared distributed training cluster using _**Connections**_ stanza in KubeDirector Cluster manifest YAML file. This local Jupyter Notebook will be used in the next lab to do model training on the tenant-shared training cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
