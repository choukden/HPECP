{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline with KubeDirector - Lab 4\n",
    "## Register the trained model and deploy it to a deployment engine service to serve predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lab workflow:**\n",
    "\n",
    "In this lab:\n",
    "\n",
    "1. As tenant user, you will register the trained model in the Kubernetes cluster by creating a ConfigMap resource in the Kubernetes cluster. The ConfigMap object stores metadata about the trained model to be used to make predictions. It contains information such as model name, description, versioning, trained model (serialized) file path (XGB.pickle.dat), and the scoring path that locates a Python script (XGB_Scoring.py) that will be used by the inference deployment engine to deserialize and process the model to generate predicted values (i.e.: predictions) from new input data. \n",
    "\n",
    "2. You will then deploy an inference deployment engine cluster using KubeDirector. The inference deployment-engine cluster loads information about the registered model from the ConfigMap object. The inference deployment engine is used to stand up services that will allow client to draw predictions from the model you have registered.\n",
    "\n",
    "**Definitions:**\n",
    "\n",
    "- *Model registry:* The trained model to be used is identified and characterized in the Kubernetes cluster by a ConfigMap resource. The integrated model registry enables version tracking and seamless updates to models in production.\n",
    "\n",
    "- *Model inferences:* The trained model is deployed to a target \"inference deployment engine\" KubeDirector cluster environment in the Kubernetes cluster to serve predictions and for answering prediction queries from the trained model(s) you registered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the environment:\n",
    "\n",
    "Let's first define the environment variables needed to execute this lab part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your studentId is: student74\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# environment variables to be verified by the student\n",
    "#\n",
    "studentId=\"student{{ STDID }}\" # your Jupyter Notebook student Identifier (i.e.: student<xx>)\n",
    "\n",
    "studentId=\"student74\"\n",
    "\n",
    "# fixed environment variables setup by the HPE ECP lab administrator - Please DO NOT MODIFY!!\n",
    "\n",
    "gateway_host=\"{{ HPEECPGWNAME }}\"\n",
    "Internet_access=\"{{ JPHOSTEXT }}\"\n",
    "\n",
    "gateway_host=\"hpecpgw1.hp.local\"\n",
    "Internet_access=\"notebooks2.hpedev.io\"\n",
    "\n",
    "JupyterNotebookApp=\"cr-cluster-jupyter-notebook.yaml\" # the Jupyter Notebook KD App manifest you will deploy to build your model\n",
    "DeploymentEngineApp=\"cr-cluster-endpoint-wrapper.yaml\" # the Deployment engine KD App manifest you will deploy to query your model for answers \n",
    "PipelineConfigMap=\"ml-pipeline-configmap.yaml\" # ConfigMap manifest used to register the trained model version 1 \n",
    "TrainingModel=\"model-${studentId}\"\n",
    "\n",
    "echo \"Your studentId is: \"$studentId "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register your trained model\n",
    "\n",
    "You will need to register the trained model in Kubernetes cluster by creating a ConfigMap resource. The ConfigMap object will be used later in a **Connection** stanza to attach the trained model to the inference deployment engine cluster. The ConfigMap object stores metadata about the trained model to be used to make predictions. It contains information such as:\n",
    "* the model name, \n",
    "* a label: **kubedirector.hpe.com/cmType: \"model\"**\n",
    "* a description, \n",
    "* a versioning (for example 1 for the first version of the model) \n",
    "* the full path to the trained model (serialized) file (XGB.pickle.dat),\n",
    "* the full path to the scoring (prediction) script (XGB_Scoring.py) that will be used by the inference deployment engine to load (deserialize) the model and process the model to make predictions from new data (this process is also known as **_scoring_**, hence the name of this python script file). \n",
    "\n",
    "Let's make sure the model registry is unique among the tenant users. Here we replace the string \"example\" with your \"studentId\" in the Configmap resource manifest file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "  name: model-student74\n",
      "  labels:\n",
      "    kubedirector.hpe.com/cmType: \"model\"\n",
      "data:\n",
      "  name: model-student74\n",
      "  description: \"student74 model\"\n",
      "  model-version: \"1\"\n",
      "  path: /bd-fs-mnt/TenantShare/repo/models/NYCTaxi/student74/XGB.pickle.dat\n",
      "  scoring-path: /bd-fs-mnt/TenantShare/repo/code/NYCTaxi/student74/XGB_Scoring.py"
     ]
    }
   ],
   "source": [
    "sed -i \"s/example/${studentId}/g\" $PipelineConfigMap\n",
    "cat $PipelineConfigMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/model-student74 created\n"
     ]
    }
   ],
   "source": [
    "kubectl apply -f $PipelineConfigMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME              DATA   AGE\n",
      "model-student74   5      2s\n"
     ]
    }
   ],
   "source": [
    "kubectl get configmap $TrainingModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying your model to a deployment engine environment to serve predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy an instance of the deployment-engine KubeDirector application:\n",
    "Next, you will deploy an instance of the **deployment-engine** KubeDirector application (kdapp) by creating a KubeDirector virtual cluster (kdcluster). The deployment engine is used to stand up services that will allow clients to draw predictions from the model you have just registered with the ConfigMap resource in the Kubernetes cluster.\n",
    "\n",
    "The inference deployment engine cluster is a set of microservices with a REST API to serve online predictions. The deployment engine cluster exposes network service endpoints such as a **LoadBalancer and a RESTServer** with token-based authorization. \n",
    "\n",
    "Let's make sure your application deployment name will be unique among the tenant users. Here we replace the string \"example\" with your \"studentId\" in the application manifest file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                AGE\n",
      "deployment-engine   22h\n"
     ]
    }
   ],
   "source": [
    "kubectl get kdapp deployment-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"kubedirector.hpe.com/v1beta1\"\n",
      "kind: \"KubeDirectorCluster\"\n",
      "metadata: \n",
      "  name: \"inference-server-student74\"\n",
      "\n",
      "spec:\n",
      "  app: deployment-engine\n",
      "  appCatalog: \"local\"\n",
      "  connections: \n",
      "    #secrets: \n",
      "      #- \n",
      "        #\"some secrets\"\n",
      "    configmaps: \n",
      "      - \"model-student74\" \n",
      "        #\"some configmaps\"\n",
      "    #clusters: \n",
      "      #-\n",
      "        #\"some clusters\"\n",
      "  roles:\n",
      "  - id: RESTServer\n",
      "    members: 1\n",
      "    resources:\n",
      "      requests:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "      limits:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "  - id: LoadBalancer\n",
      "    members: 1\n",
      "    resources:\n",
      "      requests:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "      limits:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"    \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "sed -i \"s/example/${studentId}/g\" $DeploymentEngineApp\n",
    "cat $DeploymentEngineApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** _Similar to how the Jupyter Notebook kdcluster yaml file was modified (Lab 2), this kdcluster manifest file includes the **Connections** stanza. This connection stanza here is used to attach your model from the model registry (that is the ConfigMap object) to the inference deployment engine cluster. The inference deployment engine cluster will load information about the registered model from the ConfigMap object into a JSON file (**/etc/guestconfig/configmeta.json**) within the deployment engine cluster containers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubedirectorcluster.kubedirector.hpe.com/inference-server-student74 created\n"
     ]
    }
   ],
   "source": [
    "kubectl apply -f $DeploymentEngineApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds, you should get the response message to your K8s API request: *kubedirectorcluster/Your-instance-name created*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the deployed KubeDirector application instance: \n",
    "Your application will be represented in the Kubernetes cluster by a custom resource of type **KubeDirectorCluster (kdcluster)**, with the name that was indicated inside the YAML file used to create it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                         AGE\n",
      "inference-server-student74   7s\n"
     ]
    }
   ],
   "source": [
    "clusterName=\"inference-server-${studentId}\"\n",
    "kubectl get kdcluster $clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the instance of the KubeDirector Application, you can use the `kubectl describe kdcluster` command below to observe its status and the standard Kubernetes resources that compose the application virtual cluster (statefulsets, pods, services, persistent volume claim if any), as well as any events logged against it.\n",
    "\n",
    "The virtual cluster status indicates its overall \"state\" (top-level property of the status object). It should have a value of **\"configured\"**. \n",
    "\n",
    "> **Note:** _The first time a virtual cluster of a given KubeDirector Application type is created, it may take some minutes to reach its **\"configured\"** state, as the relevant Docker image must be downloaded and imported._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat the command below until the kdcluster is in state \"configured\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         inference-server-student74\n",
      "Namespace:    k8smltenant\n",
      "Labels:       <none>\n",
      "Annotations:  <none>\n",
      "API Version:  kubedirector.hpe.com/v1beta1\n",
      "Kind:         KubeDirectorCluster\n",
      "Metadata:\n",
      "  Creation Timestamp:  2020-12-16T18:35:15Z\n",
      "  Finalizers:\n",
      "    kubedirector.hpe.com/cleanup\n",
      "  Generation:        1\n",
      "  Resource Version:  310354\n",
      "  Self Link:         /apis/kubedirector.hpe.com/v1beta1/namespaces/k8smltenant/kubedirectorclusters/inference-server-student74\n",
      "  UID:               9ba7c2ba-077d-4ead-b535-697c2f8252c3\n",
      "Spec:\n",
      "  App:          deployment-engine\n",
      "  App Catalog:  local\n",
      "  Connections:\n",
      "    Configmaps:\n",
      "      model-student74\n",
      "  Naming Scheme:  UID\n",
      "  Roles:\n",
      "    Id:       RESTServer\n",
      "    Members:  1\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "      Requests:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "    Id:          LoadBalancer\n",
      "    Members:     1\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "      Requests:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "  Service Type:  NodePort\n",
      "Status:\n",
      "  Cluster Service:       kdhs-lpxwg\n",
      "  Generation UID:        33f98088-c959-41bd-9361-4ab391b485a0\n",
      "  Last Connection Hash:  6e8c5f256cc06bc2bf5c4272272f471d\n",
      "  Last Node ID:          2\n",
      "  Member State Rollup:\n",
      "    Config Errors:         false\n",
      "    Members Down:          false\n",
      "    Members Initializing:  false\n",
      "    Members Restarting:    false\n",
      "    Members Waiting:       false\n",
      "    Membership Changing:   false\n",
      "  Roles:\n",
      "    Id:  RESTServer\n",
      "    Members:\n",
      "      Auth Token:  20941723f2cac5d91cf56a8d72ab6ed1\n",
      "      Node ID:     1\n",
      "      Pod:         kdss-dqscg-0\n",
      "      Service:     s-kdss-dqscg-0\n",
      "      State:       configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  1\n",
      "        Last Configured Container:    docker://5ee097790ab203bfe9ffe25526d75aa1215f4c05903c7fc6b9bc498b88e70a14\n",
      "        Last Connection Version:      0\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        1\n",
      "    Stateful Set:                     kdss-dqscg\n",
      "    Id:                               LoadBalancer\n",
      "    Members:\n",
      "      Auth Token:  88f08f4023855961a2d40e8b12abd888\n",
      "      Node ID:     2\n",
      "      Pod:         kdss-2xg9c-0\n",
      "      Service:     s-kdss-2xg9c-0\n",
      "      State:       configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  1\n",
      "        Last Configured Container:    docker://e4956a88fe9b5ff7f973bfd59a69a19d5388ab1d0bdfe12afc2c719519c48bdc\n",
      "        Last Connection Version:      0\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        1\n",
      "    Stateful Set:                     kdss-2xg9c\n",
      "  Spec Generation To Process:         1\n",
      "  State:                              configured\n",
      "Events:\n",
      "  Type    Reason   Age                From          Message\n",
      "  ----    ------   ----               ----          -------\n",
      "  Normal  Cluster  2m                 kubedirector  new\n",
      "  Normal  Role     2m                 kubedirector  creating role{RESTServer}\n",
      "  Normal  Role     2m                 kubedirector  creating role{LoadBalancer}\n",
      "  Normal  Cluster  2m                 kubedirector  Annotation initialized to 1\n",
      "  Normal  Role     118s               kubedirector  changing replicas count for role{RESTServer}: 0 -> 1\n",
      "  Normal  Role     118s               kubedirector  changing replicas count for role{LoadBalancer}: 0 -> 1\n",
      "  Normal  Role     118s               kubedirector  waiting for replicas count for role{LoadBalancer}: 0 -> 1\n",
      "  Normal  Role     118s               kubedirector  waiting for replicas count for role{RESTServer}: 0 -> 1\n",
      "  Normal  Member   68s                kubedirector  initial config ongoing for member{kdss-dqscg-0} in role{RESTServer}\n",
      "  Normal  Member   46s                kubedirector  initial config done for member{kdss-dqscg-0} in role{RESTServer}\n",
      "  Normal  Member   45s (x3 over 46s)  kubedirector  initial config ongoing for member{kdss-2xg9c-0} in role{LoadBalancer}\n",
      "  Normal  Member   15s                kubedirector  initial config done for member{kdss-2xg9c-0} in role{LoadBalancer}\n",
      "  Normal  Cluster  15s                kubedirector  stable\n"
     ]
    }
   ],
   "source": [
    "kubectl describe kdcluster $clusterName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               READY   STATUS    RESTARTS   AGE\n",
      "pod/kdss-2xg9c-0   1/1     Running   0          109s\n",
      "pod/kdss-dqscg-0   1/1     Running   0          109s\n",
      "\n",
      "NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                          AGE\n",
      "service/kdhs-lpxwg       ClusterIP   None             <none>        8888/TCP                                         111s\n",
      "service/s-kdss-2xg9c-0   NodePort    10.102.185.101   <none>        8081:32640/TCP,10001:32472/TCP,32700:31713/TCP   111s\n",
      "service/s-kdss-dqscg-0   NodePort    10.110.81.198    <none>        22:32254/TCP,10001:32596/TCP                     111s\n",
      "\n",
      "NAME                          READY   AGE\n",
      "statefulset.apps/kdss-2xg9c   1/1     111s\n",
      "statefulset.apps/kdss-dqscg   1/1     111s\n"
     ]
    }
   ],
   "source": [
    "kubectl get all -l kubedirector.hpe.com/kdcluster=$clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your instance of the KubeDirector Application virtual cluster is made up of a **StatefulSet**, a **POD** (a cluster node) and a **NodePort Service** per service role member (LoadBalancer, RESTServer), and a **headless service** for the application cluster.   \n",
    "\n",
    "* The ClusterIP service is the headless service required by a Kubernetes StatefulSet to work. It maintains a stable POD network identity (i.e.: persistence of the hostname of the PODs across PODs rescheduling).\n",
    "* The NodePort services expose the LoadBalancer and RESTServer application services with token-based authorization outside the Kubernetes cluster. \n",
    "\n",
    "HPE Ezmeral Container Platform automatically maps the NodePort Service endpoints to the HPE Ezmeral Container Platform gateway (haproxy) host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, follow the instructions in Lab 5 to serve prediction queries\n",
    "\n",
    "* [Lab 5 Model Serving](5-WKSHP-K8s-ML-Pipeline-Model-Serving.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we have shown you how you, **as tenant user**, can register a trained model in Kubernetes cluster with relevant model information and attach the model from model registry to a deployment engine cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
