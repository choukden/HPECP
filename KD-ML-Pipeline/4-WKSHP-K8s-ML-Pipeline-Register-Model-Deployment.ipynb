{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline with KubeDirector - Lab 4\n",
    "## Move the trained model to production: Register the trained model and deploy it to a deployment engine service to serve predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lab workflow**\n",
    "\n",
    "After you have trained your ML model and saved it to a file in the central repository, it is time to move it to production by creating a service end-point in the form of an API service that client applications can access to serve the model and make predictions. \n",
    "\n",
    "Delivering an ML model to production is a two-step process. We will cover both of these steps in this lab.\n",
    "\n",
    "1. As tenant user, you will first register the trained model in the Kubernetes cluster by creating a ConfigMap resource in the Kubernetes cluster. The ConfigMap object stores metadata about the trained model to be used to make predictions. It contains information such as model name, description, versioning, trained model file path (XGB.pickle.dat), and the scoring path. The scoring path locates a Python script (XGB_Scoring.py) that is used to generate predictions from new data.  \n",
    "\n",
    "2. You will then deploy a deployment engine cluster using KubeDirector. The deployment engine cluster loads information about the registered model from the ConfigMap object. The deployment engine is a set of microservices with a REST API that will allow clients to draw predictions from the registered model on new input data.\n",
    "\n",
    "**Definitions:**\n",
    "\n",
    "- *Model registry:* The trained model to be used is identified and characterized in the Kubernetes cluster by a ConfigMap resource. The integrated model registry enables version tracking and seamless updates to models in production.\n",
    "\n",
    "- *Model predictions:* The trained model is deployed to a target _\"deployment engine\"_ KubeDirector cluster environment in the Kubernetes cluster to serve predictions and for answering prediction queries from the trained model(s) you registered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1- Initialize the environment**\n",
    "\n",
    "Let's first define the environment variables needed to execute this part of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your studentId is: student75\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# environment variables\n",
    "#\n",
    "studentId=\"student75\" # your Jupyter Notebook student Identifier (i.e.: student<xx>)\n",
    "\n",
    "gateway_host=\"haecpgtw.etc.fr.comm.hpecorp.net\"\n",
    "Internet_access=\"notebooks.hpedev.io\"\n",
    "\n",
    "JupyterNotebookApp=\"cr-cluster-jupyter-notebook.yaml\" # the Jupyter Notebook KD App manifest you will deploy to build your model\n",
    "DeploymentEngineApp=\"cr-cluster-endpoint-wrapper.yaml\" # the Deployment engine KD App manifest you will deploy to query your model for answers \n",
    "PipelineConfigMap=\"ml-pipeline-configmap.yaml\" # ConfigMap manifest used to register the trained model version 1 \n",
    "TrainingModel=\"model-${studentId}\"\n",
    "\n",
    "echo \"Your studentId is: \"$studentId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2- Register your trained model**\n",
    "\n",
    "You will need to register the trained model in the Kubernetes cluster by creating a ConfigMap resource. The ConfigMap object will be used later in a **_Connections_** stanza to attach the trained model to the deployment engine cluster. The ConfigMap object stores metadata about the trained model to be used to make predictions. It contains information such as:\n",
    "* the model name, \n",
    "* a label: **kubedirector.hpe.com/cmType: \"model\"**\n",
    "* a description, \n",
    "* a versioning (for example 1 for the first version of the model) \n",
    "* the full path to the trained model (serialized) file (XGB.pickle.dat),\n",
    "* the full path to the scoring (prediction) script (XGB_Scoring.py) that will be used by the deployment engine to load (deserialize) the model and process the model to make predictions from new data (this process is also known as **_scoring_**, hence the name of this python script file). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the ConfigMap resource using a YAML manifest file:\n",
    "The `kubectl apply -f ManifestAppFile` command is used to create the ConfigMap resource. The application manifest is a YAML file that describes the registry information for the trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "  name: model-student75\n",
      "  labels:\n",
      "    kubedirector.hpe.com/cmType: \"model\"\n",
      "data:\n",
      "  name: model-student75\n",
      "  description: \"student75 model\"\n",
      "  model-version: \"1\"\n",
      "  path: /bd-fs-mnt/TenantShare/repo/models/NYCTaxi/student75/XGB.pickle.dat\n",
      "  scoring-path: /bd-fs-mnt/TenantShare/repo/code/NYCTaxi/student75/XGB_Scoring.py"
     ]
    }
   ],
   "source": [
    "cat $PipelineConfigMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/model-student75 created\n"
     ]
    }
   ],
   "source": [
    "kubectl apply -f $PipelineConfigMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME              DATA   AGE\n",
      "model-student75   5      1s\n"
     ]
    }
   ],
   "source": [
    "kubectl get configmap $TrainingModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3- Deploying your model to a deployment engine environment to serve predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the manifest file and deploy an instance of the _deployment-engine_ KubeDirector application:\n",
    "You will now deploy an instance of the _**deployment-engine**_ KubeDirector application (kdapp) by creating a KubeDirector virtual cluster (kdcluster). The deployment engine cluster environment is used to stand up services that will allow clients to draw predictions from the model you have just registered with the ConfigMap resource in the Kubernetes cluster.\n",
    "\n",
    "The deployment engine cluster is a set of microservices with a REST API to serve online predictions. The deployment engine cluster exposes network service endpoints such as a **LoadBalancer and a RESTServer** with token-based authorization. \n",
    "\n",
    "Like any other containerized application deployment on Kubernetes, the `kubectl apply -f ManifestAppFile` command is used to deploy the kdcluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** _Similar to how the Jupyter Notebook kdcluster yaml file was modified (Lab 2), this kdcluster manifest file includes the **Connections** stanza. The Connections stanza here is used to attach your model from the model registry (that is the ConfigMap object) to the deployment engine cluster. The deployment engine cluster will load information about the registered model from the ConfigMap object into a JSON file (**/etc/guestconfig/configmeta.json**) within the deployment engine cluster containers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"kubedirector.hpe.com/v1beta1\"\n",
      "kind: \"KubeDirectorCluster\"\n",
      "metadata: \n",
      "  name: \"inference-server-student75\"\n",
      "\n",
      "spec:\n",
      "  app: deployment-engine\n",
      "  appCatalog: \"local\"\n",
      "  connections: \n",
      "    #secrets: \n",
      "      #- \n",
      "        #\"some secrets\"\n",
      "    configmaps: \n",
      "      - \"model-student75\" \n",
      "        #\"some configmaps\"\n",
      "    #clusters: \n",
      "      #-\n",
      "        #\"some clusters\"\n",
      "  roles:\n",
      "  - id: RESTServer\n",
      "    members: 1\n",
      "    resources:\n",
      "      requests:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "      limits:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "  - id: LoadBalancer\n",
      "    members: 1\n",
      "    resources:\n",
      "      requests:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "      limits:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"    \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "cat $DeploymentEngineApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubedirectorcluster.kubedirector.hpe.com/inference-server-student75 created\n"
     ]
    }
   ],
   "source": [
    "kubectl apply -f $DeploymentEngineApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds, you should get the response message: *kubedirectorcluster/Your-instance-name created*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4- Inspect the deployed KubeDirector application instance** \n",
    "Your application will be represented in the Kubernetes cluster by a custom resource of type **KubeDirectorCluster (kdcluster)**, with the name that was indicated inside the YAML file used to create it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                         AGE\n",
      "inference-server-student75   3s\n"
     ]
    }
   ],
   "source": [
    "clusterName=\"inference-server-${studentId}\"\n",
    "kubectl get kdcluster $clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the instance of the KubeDirector application, you can use the `kubectl describe kdcluster` command below to observe its status and any events logged against it.\n",
    "\n",
    "The virtual cluster status indicates its overall \"state\" (top-level property of the status object). It should have a value of **\"configured\"**. \n",
    "\n",
    "> **Note:** _The first time a virtual cluster of a given KubeDirector application type is created, it may take several minutes to reach its **\"configured\"** state, as the relevant Docker image must be downloaded and imported._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**>Run the `kubectl describe` command below and scroll down to the `Events` section to check the overal state of your kdcluster.**\n",
    "\n",
    "**>Regularly repeat (every minute or so) the command below until the kdcluster is in state \"configured\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         inference-server-student75\n",
      "Namespace:    k8smltenant\n",
      "Labels:       <none>\n",
      "Annotations:  <none>\n",
      "API Version:  kubedirector.hpe.com/v1beta1\n",
      "Kind:         KubeDirectorCluster\n",
      "Metadata:\n",
      "  Creation Timestamp:  2021-01-14T07:48:34Z\n",
      "  Finalizers:\n",
      "    kubedirector.hpe.com/cleanup\n",
      "  Generation:        1\n",
      "  Resource Version:  9244800\n",
      "  Self Link:         /apis/kubedirector.hpe.com/v1beta1/namespaces/k8smltenant/kubedirectorclusters/inference-server-student75\n",
      "  UID:               a1b497a0-a5e0-4a81-a2a0-ea41c06adb22\n",
      "Spec:\n",
      "  App:          deployment-engine\n",
      "  App Catalog:  local\n",
      "  Connections:\n",
      "    Configmaps:\n",
      "      model-student75\n",
      "  Naming Scheme:  UID\n",
      "  Roles:\n",
      "    Id:       RESTServer\n",
      "    Members:  1\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "      Requests:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "    Id:          LoadBalancer\n",
      "    Members:     1\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "      Requests:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "  Service Type:  NodePort\n",
      "Status:\n",
      "  Cluster Service:       kdhs-5pz4s\n",
      "  Generation UID:        96eb8fb8-2c5d-4b44-98b7-104d46f69538\n",
      "  Last Connection Hash:  98c466295a9b2ce3f08e9779da4da985\n",
      "  Last Node ID:          2\n",
      "  Member State Rollup:\n",
      "    Config Errors:         false\n",
      "    Members Down:          false\n",
      "    Members Initializing:  false\n",
      "    Members Restarting:    false\n",
      "    Members Waiting:       false\n",
      "    Membership Changing:   false\n",
      "  Roles:\n",
      "    Id:  RESTServer\n",
      "    Members:\n",
      "      Auth Token:  bd95fc77c8cb9c851761aa61c6a2b25e\n",
      "      Node ID:     1\n",
      "      Pod:         kdss-cqqxh-0\n",
      "      Service:     s-kdss-cqqxh-0\n",
      "      State:       configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  1\n",
      "        Last Configured Container:    docker://82240eb8506f82e8bda7e3ad2e759cfa1129a13cfef70039eef726f6aefc4909\n",
      "        Last Connection Version:      0\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        1\n",
      "    Stateful Set:                     kdss-cqqxh\n",
      "    Id:                               LoadBalancer\n",
      "    Members:\n",
      "      Auth Token:  f89a4f9489a023631b63d203a2aa57c7\n",
      "      Node ID:     2\n",
      "      Pod:         kdss-lmhpq-0\n",
      "      Service:     s-kdss-lmhpq-0\n",
      "      State:       configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  1\n",
      "        Last Configured Container:    docker://2f0a74fd91170f6cd596970e28fc0c18598983e350a8b909d4a320aa511b2c66\n",
      "        Last Connection Version:      0\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        1\n",
      "    Stateful Set:                     kdss-lmhpq\n",
      "  Spec Generation To Process:         1\n",
      "  State:                              configured\n",
      "Events:\n",
      "  Type    Reason   Age                From          Message\n",
      "  ----    ------   ----               ----          -------\n",
      "  Normal  Cluster  107s               kubedirector  new\n",
      "  Normal  Role     107s               kubedirector  creating role{RESTServer}\n",
      "  Normal  Role     107s               kubedirector  creating role{LoadBalancer}\n",
      "  Normal  Cluster  107s               kubedirector  Annotation initialized to 1\n",
      "  Normal  Role     104s               kubedirector  changing replicas count for role{RESTServer}: 0 -> 1\n",
      "  Normal  Role     104s               kubedirector  changing replicas count for role{LoadBalancer}: 0 -> 1\n",
      "  Normal  Role     104s               kubedirector  waiting for replicas count for role{LoadBalancer}: 0 -> 1\n",
      "  Normal  Role     104s               kubedirector  waiting for replicas count for role{RESTServer}: 0 -> 1\n",
      "  Normal  Member   62s                kubedirector  initial config ongoing for member{kdss-cqqxh-0} in role{RESTServer}\n",
      "  Normal  Member   43s                kubedirector  initial config done for member{kdss-cqqxh-0} in role{RESTServer}\n",
      "  Normal  Member   42s (x3 over 43s)  kubedirector  initial config ongoing for member{kdss-lmhpq-0} in role{LoadBalancer}\n",
      "  Normal  Member   12s                kubedirector  initial config done for member{kdss-lmhpq-0} in role{LoadBalancer}\n",
      "  Normal  Cluster  12s                kubedirector  stable\n"
     ]
    }
   ],
   "source": [
    "kubectl describe kdcluster $clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `kubectl get all` command that matches against a value of the **kubedirector.hpe.com/kdcluster=YourClusterApplicationName** label to observe the standard Kubernetes resources that compose the application virtual cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               READY   STATUS    RESTARTS   AGE\n",
      "pod/kdss-cqqxh-0   1/1     Running   0          112s\n",
      "pod/kdss-lmhpq-0   1/1     Running   0          112s\n",
      "\n",
      "NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                          AGE\n",
      "service/kdhs-5pz4s       ClusterIP   None             <none>        8888/TCP                                         114s\n",
      "service/s-kdss-cqqxh-0   NodePort    10.106.52.192    <none>        22:31782/TCP,10001:32474/TCP                     114s\n",
      "service/s-kdss-lmhpq-0   NodePort    10.104.175.139   <none>        8081:32312/TCP,10001:30541/TCP,32700:30195/TCP   114s\n",
      "\n",
      "NAME                          READY   AGE\n",
      "statefulset.apps/kdss-cqqxh   1/1     115s\n",
      "statefulset.apps/kdss-lmhpq   1/1     115s\n"
     ]
    }
   ],
   "source": [
    "kubectl get all -l kubedirector.hpe.com/kdcluster=$clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your instance of the KubeDirector Application virtual cluster is made up of a **StatefulSet**, a **POD** (a cluster node) and a **NodePort Service** per service role member (LoadBalancer, RESTServer), and a **headless service** for the application cluster.   \n",
    "\n",
    "* The ClusterIP service is the headless service required by a Kubernetes StatefulSet to work. It maintains a stable POD network identity (i.e.: persistence of the hostname of the PODs across PODs rescheduling).\n",
    "* The NodePort services expose the LoadBalancer and RESTServer application services with token-based authorization outside the Kubernetes cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, follow the instructions in Lab 5 to serve prediction queries.\n",
    "\n",
    "* [Lab 5 Model Serving](5-WKSHP-K8s-ML-Pipeline-Model-Serving.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how you can deliver a trained model to production and make it available for answering prediction queries. You first registered the trained model in the Kubernetes cluster with relevant model information in a ConfigMap resource. You then deployed the registered model to a target deployment engine environment that exposes a REST API service endpoint to serve predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
