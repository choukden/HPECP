{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline with KubeDirector - Lab 5\n",
    "## Serving prediction queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lab workflow:**\n",
    "\n",
    "You have built and trained a model from a dataset, register the trained model and deployed it in a deployment-engine kdcluster. Now it is time to make predictions (i.e.: _how long my taxi ride take?_) with new data. The **LoadBalancer** service port on the inference deployment engine can now be used to serve REST API queries using the trained model and make predictions. \n",
    "\n",
    "In this lab, you will use kubectl commands in the context of your tenant user account and get the LoadBalancer network service endpoints with token-based authentication of your inference deployment engine. \n",
    "\n",
    "You will then use a script in **_cURL_** for making queries to your prediction service. \n",
    "\n",
    "Finally, you will experience the **dynamic** aspect of your ML pipeline.\n",
    "\n",
    "**Definitions:**\n",
    "\n",
    "- *Model inferences:* The trained model is deployed to a target \"inference deployment engine\" KubeDirector cluster environment in the Kubernetes cluster to serve predictions and for answering prediction queries from the trained model you registered.\n",
    "\n",
    "- *Scoring:* Scoring denotes the process of generating predicted values from new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the environment:\n",
    "\n",
    "Let's first define the environment variables needed to execute this lab part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your studentId is: student74\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# environment variables to be verified by the student\n",
    "#\n",
    "studentId=\"student{{ STDID }}\" # your Jupyter Notebook student Identifier (i.e.: student<xx>)\n",
    "\n",
    "studentId=\"student74\"\n",
    "\n",
    "# fixed environment variables setup by the HPE ECP lab administrator - Please DO NOT MODIFY!!\n",
    "\n",
    "gateway_host=\"{{ HPEECPGWNAME }}\"\n",
    "Internet_access=\"{{ JPHOSTEXT }}\"\n",
    "\n",
    "gateway_host=\"hpecpgw1.hp.local\"\n",
    "Internet_access=\"notebooks2.hpedev.io\"\n",
    "\n",
    "JupyterNotebookApp=\"cr-cluster-jupyter-notebook.yaml\" # the Jupyter Notebook KD App manifest you will deploy to build your model\n",
    "DeploymentEngineApp=\"cr-cluster-endpoint-wrapper.yaml\" # the Deployment engine KD App manifest you will deploy to query your model for answers \n",
    "PipelineConfigMap=\"ml-pipeline-configmap.yaml\" # ConfigMap manifest used to register the trained model version 1 \n",
    "PipelineConfigMapv2=\"ml-pipeline-configmap-v2.yaml\" # ConfigMap manifest used to register the trained model version 2 \n",
    "#\n",
    "#\n",
    "#\n",
    "clusterName=\"inference-server-${studentId}\"\n",
    "#\n",
    "# Model registry information\n",
    "#\n",
    "TrainingModel=\"model-${studentId}\"\n",
    "modelVersion=\"1\"\n",
    "#\n",
    "echo \"Your studentId is: \"$studentId "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving queries through the Load Balancer service of the deployment engine cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the gateway mapped application service endpoint and the Authentication token of the Load Balancer of the deployment engine kdcluster:\n",
    "To get a report on all services related to a specific virtual cluster, you can use a form of **kubectl describe** that matches against a value of the **kubedirector.hpe.com/kdcluster=YourClusterApplicationName,kubedirector.hpe.com/role=LoadBalancer** label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your deployment-engine's LoadBalancer service endpoint re-mapped port is: 10151\n",
      "Your deployment-engine's LoadBalancer service endpoint is: https://hpecpgw1.hp.local:10151\n",
      "The deployment-engine's Load Balancer service authentication token is: 88f08f4023855961a2d40e8b12abd888\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Getting the access point for the HAPROXY service of the LoadBalancer (role: LoadBalancer, internal port: 32700)\n",
    "#\n",
    "LoadBalancerURL=$(kubectl describe service -l kubedirector.hpe.com/kdcluster=${clusterName},kubedirector.hpe.com/role=LoadBalancer | grep gateway/32700 | awk '{print $2}')\n",
    "LoadBalancerPort=$(echo $LoadBalancerURL | cut -d':' -f 2) # extract the gateway re-mapped port value.\n",
    "LoadBalancer_endpoint=\"https://$gateway_host:$LoadBalancerPort\"\n",
    "echo \"Your deployment-engine's LoadBalancer service endpoint re-mapped port is: \"$LoadBalancerPort\n",
    "echo \"Your deployment-engine's LoadBalancer service endpoint is: \"$LoadBalancer_endpoint\n",
    "#echo \"The LoadBalancer service endpoint URL is: https://\"$Internet_access:$RESTServerPort\n",
    "#\n",
    "# Getting the auth-token:\n",
    "#\n",
    "LoadBalancerAuthToken=$(kubectl describe service -l kubedirector.hpe.com/kdcluster=${clusterName},kubedirector.hpe.com/role=LoadBalancer | grep kd-auth-token  | awk '{print $2}' | tr -d '\\r')\n",
    "echo \"The deployment-engine's Load Balancer service authentication token is: \"$LoadBalancerAuthToken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on new data\n",
    "To make prediction, create an authenticated \"POST\" API call that is formulated as follows:  \n",
    "https://loadbalancer_endpoint/registeredModel/modelVersion/predict\n",
    "\n",
    "The query below is used to predict how long a taxi ride in NY City with attributes listed below will take:\n",
    "* pickup location: West 23rd street\n",
    "* dropoff location: Centre Market place \n",
    "* on a weekday \n",
    "* at 09:00 am \n",
    "* in February\n",
    "\n",
    ">Note: _It may take a few seconds to get the result of the REST API call_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"output\": \"The ride duration prediction is 3211.7134 seconds.\n"
     ]
    }
   ],
   "source": [
    "curl --location -k -s --request POST \"${LoadBalancer_endpoint}/${TrainingModel}/${modelVersion}/predict\" \\\n",
    "--header \"X-Auth-Token: ${LoadBalancerAuthToken}\" \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data-raw '{\n",
    "    \"use_scoring\": true,\n",
    "    \"scoring_args\": {\n",
    "        \"work\": 0,\n",
    "        \"start_latitude\": 40.57689727,\n",
    "        \"start_longitude\": -73.99047356,\n",
    "        \"end_latitude\": 40.72058154,\n",
    "        \"end_longitude\": -73.99740673,\n",
    "        \"distance\": 8,\n",
    "        \"weekday\": 1,\n",
    "        \"hour\": 9,\n",
    "        \"month_1\": 0,\n",
    "        \"month_2\": 1,\n",
    "        \"month_3\": 0,\n",
    "        \"month_4\": 0,\n",
    "        \"month_5\": 0,\n",
    "        \"month_6\": 0\n",
    "    }\n",
    "}' | python -m json.tool | grep output | cut -d'\\' -f 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: \n",
    "> * work is a boolean for work hours (1 if the ride occurs Mon-Fri 8am-5pm, 0 otherwise)\n",
    "> * start_latitude is the pickup location latitude\n",
    "> * start_longitude is the pickup location longitude\n",
    "> * end_latitude is the dropoff location latitude\n",
    "> * end_longitude is the dropoff location longitude\n",
    "> * distance is the trip distance in miles\n",
    "> * weekday is a boolean for weekday (1 if the ride occurs on Mon-Fri, 0 otherwise)\n",
    "> * hour is the hour of day (0 to 23)\n",
    "> * month_1 is a boolean if the ride is is in January (1 if true, 0 otherwise)\n",
    "> * month_2 is a boolean if the ride is is in February (1 if true, 0 otherwise)\n",
    "> * month_3 is a boolean if the ride is is in March (1 if true, 0 otherwise)\n",
    "> * month_4 is a boolean if the ride is is in April (1 if true, 0 otherwise)\n",
    "> * month_5 is a boolean if the ride is is in May (1 if true, 0 otherwise)\n",
    "> * month_6 is a boolean if the ride is is in June (1 if true, 0 otherwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving queries through the RESTServer service:\n",
    "You might want to make queries directly through the RESTServer of the deployment-engine.\n",
    "\n",
    "To get a report on all services related to a specific virtual cluster, you can use a form of **kubectl describe** that matches against a value of the **kubedirector.hpe.com/kdcluster=YourClusterApplicationName,kubedirector.hpe.com/role=RESTServer** label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RESTServer service endpoint re-mapped port is: 10149\n",
      "Your RESTServer service endpoint is: https://hpecpgw1.hp.local:10149\n",
      "The RESTServer service authentication token is: 20941723f2cac5d91cf56a8d72ab6ed1\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Getting the RESTServer service endpoint URL (role: RESTServer, internal port: 10001):\n",
    "#\n",
    "RESTServerURL=$(kubectl describe service -l kubedirector.hpe.com/kdcluster=${clusterName},kubedirector.hpe.com/role=RESTServer | grep gateway/10001 | awk '{print $3}')\n",
    "RESTServerPort=$(echo $RESTServerURL | cut -d':' -f 2) # extract the gateway re-mapped port value.\n",
    "RESTServer_endpoint=\"https://$gateway_host:$RESTServerPort\"\n",
    "echo \"The RESTServer service endpoint re-mapped port is: \"$RESTServerPort\n",
    "echo \"Your RESTServer service endpoint is: \"$RESTServer_endpoint\n",
    "#echo \"The RESTServer service endpoint URL is: https://\"$Internet_access:$RESTServerPort\n",
    "#\n",
    "# Getting the auth-token:\n",
    "#\n",
    "RESTServerAuthToken=$(kubectl describe service -l kubedirector.hpe.com/kdcluster=${clusterName},kubedirector.hpe.com/role=RESTServer | grep kd-auth-token  | awk '{print $2}' | tr -d '\\r')\n",
    "echo \"The RESTServer service authentication token is: \"$RESTServerAuthToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"output\": \"The ride duration prediction is 3211.7134 seconds.\n"
     ]
    }
   ],
   "source": [
    "curl --location -k -s --request POST \"${RESTServer_endpoint}/${TrainingModel}/${modelVersion}/predict\" \\\n",
    "--header \"X-Auth-Token: ${RESTServerAuthToken}\" \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data-raw '{\n",
    "    \"use_scoring\": true,\n",
    "    \"scoring_args\": {\n",
    "        \"work\": 0,\n",
    "        \"start_latitude\": 40.57689727,\n",
    "        \"start_longitude\": -73.99047356,\n",
    "        \"end_latitude\": 40.72058154,\n",
    "        \"end_longitude\": -73.99740673,\n",
    "        \"distance\": 8,\n",
    "        \"weekday\": 1,\n",
    "        \"hour\": 9,\n",
    "        \"month_1\": 0,\n",
    "        \"month_2\": 1,\n",
    "        \"month_3\": 0,\n",
    "        \"month_4\": 0,\n",
    "        \"month_5\": 0,\n",
    "        \"month_6\": 0\n",
    "    }\n",
    "}' | python -m json.tool | grep output | cut -d'\\' -f 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic? Did someone say Dynamic ML pipeline?\n",
    "\n",
    "Over time the accuracy of the predictions will drop, your dataset will change, your model will improve and your scoring script may change as well. The ML pipeline needs to adapt to constantly changing dataset and enhanced ML models.\n",
    "\n",
    "In this part of the lab, let's imagine you want to improve the prediction accuracy of your deployed model. You will _retrain_ your model by tuning the model parameters to get a better predictive performance and save your retrained model into a new file. You will then update the model registry information in the configMap kubernetes resource with the file path for the new trained model file and new scoring script file. \n",
    "\n",
    "#### Go back to your **local Jupyter Notebook**, and run the cell code from the section **\"Retrain the model to improve model accuracy\"**. Once your model is retrained, come back here to continue from the cell codes below to adjust the model registry information accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust the model registry information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "  name: model-student74\n",
      "  labels:\n",
      "    kubedirector.hpe.com/cmType: \"model\"\n",
      "data:\n",
      "  name: model-student74\n",
      "  description: \"student74 model\"\n",
      "  model-version: \"1\"\n",
      "  path: /bd-fs-mnt/TenantShare/repo/models/NYCTaxi/student74/XGB.picklev2.dat\n",
      "  scoring-path: /bd-fs-mnt/TenantShare/repo/code/NYCTaxi/student74/XGB_Scoringv2.py"
     ]
    }
   ],
   "source": [
    "sed -i \"s/example/${studentId}/g\" $PipelineConfigMapv2\n",
    "cat $PipelineConfigMapv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/model-student74 configured\n"
     ]
    }
   ],
   "source": [
    "kubectl apply -f $PipelineConfigMapv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the command below and check the events logged against it**\n",
    "\n",
    "In the events section at the bottom of the command output, you should notice the message:  \n",
    "_\"Connected to cluster {your deployment-engine cluster name}; updating it.\"_ \n",
    "\n",
    "KubeDirector is updating the model registry metadata information on the PODs of your deployment-engine cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         model-student74\n",
      "Namespace:    k8smltenant\n",
      "Labels:       kubedirector.hpe.com/cmType=model\n",
      "Annotations:  <none>\n",
      "\n",
      "Data\n",
      "====\n",
      "description:\n",
      "----\n",
      "student74 model\n",
      "model-version:\n",
      "----\n",
      "1\n",
      "name:\n",
      "----\n",
      "model-student74\n",
      "path:\n",
      "----\n",
      "/bd-fs-mnt/TenantShare/repo/models/NYCTaxi/student74/XGB.picklev2.dat\n",
      "scoring-path:\n",
      "----\n",
      "/bd-fs-mnt/TenantShare/repo/code/NYCTaxi/student74/XGB_Scoringv2.py\n",
      "Events:\n",
      "  Type    Reason   Age   From          Message\n",
      "  ----    ------   ----  ----          -------\n",
      "  Normal  Cluster  3s    kubedirector  connected to cluster {inference-server-student74}; updating it\n"
     ]
    }
   ],
   "source": [
    "kubectl describe configmap $TrainingModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the command below and check the events logged against it** \n",
    "  \n",
    "In the events section at the bottom of the command output, you should notice the message:  \n",
    "\n",
    "_\"connected configmap has changes, updated context for the PODs of your instance of the deployment engine cluster\"._ \n",
    "\n",
    "#### By changing the configMap, your entire ML pipeline will be reconciled by KubeDirector operator for you, while the containers of your deployment-engine cluster instance remain running. **This is what makes your ML pipeline created with KubeDirector very dynamic.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         inference-server-student74\n",
      "Namespace:    k8smltenant\n",
      "Labels:       <none>\n",
      "Annotations:  kubedirector.hpe.com/connUpdateCounter: 1\n",
      "              kubedirector.hpe.com/hashChangeCounter: 1\n",
      "API Version:  kubedirector.hpe.com/v1beta1\n",
      "Kind:         KubeDirectorCluster\n",
      "Metadata:\n",
      "  Creation Timestamp:  2020-12-16T18:35:15Z\n",
      "  Finalizers:\n",
      "    kubedirector.hpe.com/cleanup\n",
      "  Generation:        1\n",
      "  Resource Version:  311614\n",
      "  Self Link:         /apis/kubedirector.hpe.com/v1beta1/namespaces/k8smltenant/kubedirectorclusters/inference-server-student74\n",
      "  UID:               9ba7c2ba-077d-4ead-b535-697c2f8252c3\n",
      "Spec:\n",
      "  App:          deployment-engine\n",
      "  App Catalog:  local\n",
      "  Connections:\n",
      "    Configmaps:\n",
      "      model-student74\n",
      "  Naming Scheme:  UID\n",
      "  Roles:\n",
      "    Id:       RESTServer\n",
      "    Members:  1\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "      Requests:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "    Id:          LoadBalancer\n",
      "    Members:     1\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "      Requests:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "  Service Type:  NodePort\n",
      "Status:\n",
      "  Cluster Service:       kdhs-lpxwg\n",
      "  Generation UID:        d36f7b95-aba0-4ee3-a2d6-9a99182e1b24\n",
      "  Last Connection Hash:  26cd63b8f8a1e67ba390f4621cd393f5\n",
      "  Last Node ID:          2\n",
      "  Member State Rollup:\n",
      "    Config Errors:         false\n",
      "    Members Down:          false\n",
      "    Members Initializing:  false\n",
      "    Members Restarting:    false\n",
      "    Members Waiting:       false\n",
      "    Membership Changing:   false\n",
      "  Roles:\n",
      "    Id:  RESTServer\n",
      "    Members:\n",
      "      Auth Token:  20941723f2cac5d91cf56a8d72ab6ed1\n",
      "      Node ID:     1\n",
      "      Pod:         kdss-dqscg-0\n",
      "      Service:     s-kdss-dqscg-0\n",
      "      State:       configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  2\n",
      "        Last Configured Container:    docker://5ee097790ab203bfe9ffe25526d75aa1215f4c05903c7fc6b9bc498b88e70a14\n",
      "        Last Connection Version:      1\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        2\n",
      "    Stateful Set:                     kdss-dqscg\n",
      "    Id:                               LoadBalancer\n",
      "    Members:\n",
      "      Auth Token:  88f08f4023855961a2d40e8b12abd888\n",
      "      Node ID:     2\n",
      "      Pod:         kdss-2xg9c-0\n",
      "      Service:     s-kdss-2xg9c-0\n",
      "      State:       configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  2\n",
      "        Last Configured Container:    docker://e4956a88fe9b5ff7f973bfd59a69a19d5388ab1d0bdfe12afc2c719519c48bdc\n",
      "        Last Connection Version:      1\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        2\n",
      "    Stateful Set:                     kdss-2xg9c\n",
      "  Spec Generation To Process:         2\n",
      "  State:                              configured\n",
      "Events:\n",
      "  Type    Reason     Age                    From          Message\n",
      "  ----    ------     ----                   ----          -------\n",
      "  Normal  Role       7m49s                  kubedirector  creating role{RESTServer}\n",
      "  Normal  Role       7m49s                  kubedirector  creating role{LoadBalancer}\n",
      "  Normal  Cluster    7m49s                  kubedirector  new\n",
      "  Normal  Role       7m47s                  kubedirector  waiting for replicas count for role{LoadBalancer}: 0 -> 1\n",
      "  Normal  Role       7m47s                  kubedirector  changing replicas count for role{RESTServer}: 0 -> 1\n",
      "  Normal  Role       7m47s                  kubedirector  changing replicas count for role{LoadBalancer}: 0 -> 1\n",
      "  Normal  Role       7m47s                  kubedirector  waiting for replicas count for role{RESTServer}: 0 -> 1\n",
      "  Normal  Member     6m57s                  kubedirector  initial config ongoing for member{kdss-dqscg-0} in role{RESTServer}\n",
      "  Normal  Member     6m35s                  kubedirector  initial config done for member{kdss-dqscg-0} in role{RESTServer}\n",
      "  Normal  Member     6m34s (x3 over 6m35s)  kubedirector  initial config ongoing for member{kdss-2xg9c-0} in role{LoadBalancer}\n",
      "  Normal  Member     6m4s                   kubedirector  initial config done for member{kdss-2xg9c-0} in role{LoadBalancer}\n",
      "  Normal  Cluster    13s (x2 over 7m49s)    kubedirector  Annotation initialized to 1\n",
      "  Normal  ConfigMap  13s                    kubedirector  connected configmap {model-student74} has changed\n",
      "  Normal  Cluster    13s                    kubedirector  Updated context\n",
      "  Normal  Cluster    10s                    kubedirector  --reconnect will be called for pod : kdss-dqscg-0\n",
      "  Normal  Cluster    6s                     kubedirector  --reconnect will be called for pod : kdss-2xg9c-0\n",
      "  Normal  Cluster    3s (x2 over 6m4s)      kubedirector  stable\n"
     ]
    }
   ],
   "source": [
    "kubectl describe kdcluster $clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make another query using your retrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"output\": \"The ride duration prediction is 3412.6396 seconds.\n"
     ]
    }
   ],
   "source": [
    "curl --location -k -s --request POST \"${LoadBalancer_endpoint}/${TrainingModel}/${modelVersion}/predict\" \\\n",
    "--header \"X-Auth-Token: ${LoadBalancerAuthToken}\" \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data-raw '{\n",
    "    \"use_scoring\": true,\n",
    "    \"scoring_args\": {\n",
    "        \"work\": 0,\n",
    "        \"start_latitude\": 40.57689727,\n",
    "        \"start_longitude\": -73.99047356,\n",
    "        \"end_latitude\": 40.72058154,\n",
    "        \"end_longitude\": -73.99740673,\n",
    "        \"distance\": 8,\n",
    "        \"weekday\": 1,\n",
    "        \"hour\": 9,\n",
    "        \"month_1\": 0,\n",
    "        \"month_2\": 1,\n",
    "        \"month_3\": 0,\n",
    "        \"month_4\": 0,\n",
    "        \"month_5\": 0,\n",
    "        \"month_6\": 0\n",
    "    }\n",
    "}' | python -m json.tool | grep output | cut -d'\\' -f 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to go through some cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete your deployment engine and your local Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubedirectorcluster.kubedirector.hpe.com \"inference-server-student74\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete -f $DeploymentEngineApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap \"model-student74\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete -f $PipelineConfigMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubedirectorcluster.kubedirector.hpe.com \"jupyter-notebook-student74\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete -f $JupyterNotebookApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset the application files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"kubedirector.hpe.com/v1beta1\"\n",
      "kind: \"KubeDirectorCluster\"\n",
      "metadata:\n",
      "  name: \"jupyter-notebook-example\"\n",
      "spec:\n",
      "  app: \"jupyter-notebook-v1\"\n",
      "  appCatalog: \"local\"\n",
      "  connections: \n",
      "    #secrets: \n",
      "      #- \n",
      "        #\"some secrets\"\n",
      "    #configmaps: \n",
      "      #- \n",
      "        #\"some configmaps\"\n",
      "    clusters: \n",
      "      - \"training-engine-shared\"\n",
      "        #\"some clusters\"\n",
      "  roles:\n",
      "  - id: controller\n",
      "    resources:\n",
      "      requests:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "      limits:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "apiVersion: \"kubedirector.hpe.com/v1beta1\"\n",
      "kind: \"KubeDirectorCluster\"\n",
      "metadata: \n",
      "  name: \"inference-server-example\"\n",
      "\n",
      "spec:\n",
      "  app: deployment-engine\n",
      "  appCatalog: \"local\"\n",
      "  connections: \n",
      "    #secrets: \n",
      "      #- \n",
      "        #\"some secrets\"\n",
      "    configmaps: \n",
      "      - \"model-example\" \n",
      "        #\"some configmaps\"\n",
      "    #clusters: \n",
      "      #-\n",
      "        #\"some clusters\"\n",
      "  roles:\n",
      "  - id: RESTServer\n",
      "    members: 1\n",
      "    resources:\n",
      "      requests:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "      limits:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "  - id: LoadBalancer\n",
      "    members: 1\n",
      "    resources:\n",
      "      requests:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"\n",
      "      limits:\n",
      "        memory: \"2Gi\"\n",
      "        cpu: \"1\"    \n",
      "        \n",
      "apiVersion: v1\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "  name: model-example\n",
      "  labels:\n",
      "    kubedirector.hpe.com/cmType: \"model\"\n",
      "data:\n",
      "  name: model-example\n",
      "  description: \"example model\"\n",
      "  model-version: \"1\"\n",
      "  path: /bd-fs-mnt/TenantShare/repo/models/NYCTaxi/example/XGB.pickle.dat\n",
      "  scoring-path: /bd-fs-mnt/TenantShare/repo/code/NYCTaxi/example/XGB_Scoring.pyapiVersion: v1\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "  name: model-example\n",
      "  labels:\n",
      "    kubedirector.hpe.com/cmType: \"model\"\n",
      "data:\n",
      "  name: model-example\n",
      "  description: \"example model\"\n",
      "  model-version: \"1\"\n",
      "  path: /bd-fs-mnt/TenantShare/repo/models/NYCTaxi/example/XGB.picklev2.dat\n",
      "  scoring-path: /bd-fs-mnt/TenantShare/repo/code/NYCTaxi/example/XGB_Scoringv2.py"
     ]
    }
   ],
   "source": [
    "#reset the application deployment name in the YAML file\n",
    "sed -i \"s/${studentId}/example/g\" $JupyterNotebookApp\n",
    "sed -i \"s/${studentId}/example/g\" $DeploymentEngineApp\n",
    "sed -i \"s/${studentId}/example/g\" $PipelineConfigMap\n",
    "sed -i \"s/${studentId}/example/g\" $PipelineConfigMapv2\n",
    "cat $JupyterNotebookApp\n",
    "cat $DeploymentEngineApp\n",
    "cat $PipelineConfigMap\n",
    "cat $PipelineConfigMapv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we have shown you how you, **as tenant user** can make predictions on a trained model registered in a Kubernetes cluster. You also learned how the key use of KubeDirector applications, Clusters and Connections is what makes your ML pipeline very dynamic.\n",
    "\n",
    "\n",
    "* [Conclusion](6-Conclusion.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
