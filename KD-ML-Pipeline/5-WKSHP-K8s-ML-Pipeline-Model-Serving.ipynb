{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline with KubeDirector - Lab 5\n",
    "## Serving prediction queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lab workflow**\n",
    "\n",
    "You have built and trained a model from a dataset, register the trained model and deployed it in a deployment engine kdcluster. Now it is time to make predictions (i.e.: _how long my taxi ride take?_) with new data. The **LoadBalancer** service port on the deployment engine can now be used to serve REST API queries using the trained model and make predictions. \n",
    "\n",
    "In this lab:\n",
    "\n",
    "1. You will use kubectl commands in the context of your tenant user account and get the LoadBalancer network service endpoints with token-based authentication of your inference deployment engine. \n",
    "\n",
    "2. You will then use a script in **_cURL_** for making queries to your prediction service. \n",
    "\n",
    "\n",
    "**Definitions:**\n",
    "\n",
    "- *Model predictions:* The trained model is deployed to a target _\"deployment engine\"_ KubeDirector cluster environment in the Kubernetes cluster to serve predictions and for answering prediction queries from the trained model you registered.\n",
    "\n",
    "- *Scoring:* Scoring denotes the process of generating predicted values from new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1- Initialize the environment**\n",
    "\n",
    "Let's first define the environment variables needed to execute this part of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your studentId is: student75\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# environment variables\n",
    "#\n",
    "studentId=\"student75\" # your Jupyter Notebook student Identifier (i.e.: student<xx>)\n",
    "\n",
    "gateway_host=\"haecpgtw.etc.fr.comm.hpecorp.net\"\n",
    "Internet_access=\"notebooks.hpedev.io\"\n",
    "\n",
    "JupyterNotebookApp=\"cr-cluster-jupyter-notebook.yaml\" # the Jupyter Notebook KD App manifest you will deploy to build your model\n",
    "DeploymentEngineApp=\"cr-cluster-endpoint-wrapper.yaml\" # the Deployment engine KD App manifest you will deploy to query your model for answers \n",
    "PipelineConfigMap=\"ml-pipeline-configmap.yaml\" # ConfigMap manifest used to register the trained model version 1 \n",
    "PipelineConfigMapv2=\"ml-pipeline-configmap-v2.yaml\" # ConfigMap manifest used to register the trained model version 2 \n",
    "#\n",
    "clusterName=\"inference-server-${studentId}\"\n",
    "#\n",
    "# Model registry information\n",
    "#\n",
    "TrainingModel=\"model-${studentId}\"\n",
    "modelVersion=\"1\"\n",
    "#\n",
    "echo \"Your studentId is: \"$studentId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2- Serving queries through the Load Balancer service of the deployment engine cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the service endpoint and the Authentication token of the Load Balancer service of the deployment engine kdcluster:\n",
    "To get a report on all services related to a specific virtual cluster, you can use a form of **kubectl describe** that matches against a value of the **kubedirector.hpe.com/kdcluster=YourClusterApplicationName,kubedirector.hpe.com/role=LoadBalancer** label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your deployment-engine's LoadBalancer service endpoint re-mapped port is: 10056\n",
      "Your deployment-engine's LoadBalancer service endpoint is: https://haecpgtw.etc.fr.comm.hpecorp.net:10056\n",
      "The deployment-engine's Load Balancer service authentication token is: f89a4f9489a023631b63d203a2aa57c7\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Getting the access point for the HAPROXY service of the LoadBalancer (role: LoadBalancer, internal port: 32700)\n",
    "#\n",
    "LoadBalancerURL=$(kubectl describe service -l kubedirector.hpe.com/kdcluster=${clusterName},kubedirector.hpe.com/role=LoadBalancer | grep gateway/32700 | awk '{print $2}')\n",
    "LoadBalancerPort=$(echo $LoadBalancerURL | cut -d':' -f 2) # extract the gateway re-mapped port value.\n",
    "LoadBalancer_endpoint=\"https://$gateway_host:$LoadBalancerPort\"\n",
    "echo \"Your deployment-engine's LoadBalancer service endpoint re-mapped port is: \"$LoadBalancerPort\n",
    "echo \"Your deployment-engine's LoadBalancer service endpoint is: \"$LoadBalancer_endpoint\n",
    "#echo \"The LoadBalancer service endpoint URL is: https://\"$Internet_access:$RESTServerPort\n",
    "#\n",
    "# Getting the auth-token:\n",
    "#\n",
    "LoadBalancerAuthToken=$(kubectl describe service -l kubedirector.hpe.com/kdcluster=${clusterName},kubedirector.hpe.com/role=LoadBalancer | grep kd-auth-token  | awk '{print $2}' | tr -d '\\r')\n",
    "echo \"The deployment-engine's Load Balancer service authentication token is: \"$LoadBalancerAuthToken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3- Making predictions on new data**\n",
    "To make a prediction, you create an authenticated \"POST\" API call that is formulated as follows:  \n",
    "https://loadbalancer_endpoint/registeredModel/modelVersion/predict\n",
    "\n",
    "The query below is used to predict how long a taxi ride in NY City with attributes listed below will take:\n",
    "* pickup location: West 23rd street\n",
    "* dropoff location: Centre Market place \n",
    "* on a weekday \n",
    "* at 09:00 am \n",
    "* in February\n",
    "\n",
    ">Note: _It may take a few seconds to get the result of the REST API call_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"output\": \"The ride duration prediction is 3211.7134 seconds.\n"
     ]
    }
   ],
   "source": [
    "curl --location -k -s --request POST \"${LoadBalancer_endpoint}/${TrainingModel}/${modelVersion}/predict\" \\\n",
    "--header \"X-Auth-Token: ${LoadBalancerAuthToken}\" \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data-raw '{\n",
    "    \"use_scoring\": true,\n",
    "    \"scoring_args\": {\n",
    "        \"work\": 0,\n",
    "        \"start_latitude\": 40.57689727,\n",
    "        \"start_longitude\": -73.99047356,\n",
    "        \"end_latitude\": 40.72058154,\n",
    "        \"end_longitude\": -73.99740673,\n",
    "        \"distance\": 8,\n",
    "        \"weekday\": 1,\n",
    "        \"hour\": 9,\n",
    "        \"month_1\": 0,\n",
    "        \"month_2\": 1,\n",
    "        \"month_3\": 0,\n",
    "        \"month_4\": 0,\n",
    "        \"month_5\": 0,\n",
    "        \"month_6\": 0\n",
    "    }\n",
    "}' | python -m json.tool | grep output | cut -d'\\' -f 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new data that you provide as input have the same columns that were used to train the model, minus the outcome column. \n",
    "> Fields description:\n",
    "> * work is a boolean for work hours (1 if the ride occurs Mon-Fri 8am-5pm, 0 otherwise)\n",
    "> * start_latitude is the pickup location latitude\n",
    "> * start_longitude is the pickup location longitude\n",
    "> * end_latitude is the dropoff location latitude\n",
    "> * end_longitude is the dropoff location longitude\n",
    "> * distance is the trip distance in miles\n",
    "> * weekday is a boolean for weekday (1 if the ride occurs on Mon-Fri, 0 otherwise)\n",
    "> * hour is the hour of day (0 to 23)\n",
    "> * month_1 is a boolean if the ride is is in January (1 if true, 0 otherwise)\n",
    "> * month_2 is a boolean if the ride is is in February (1 if true, 0 otherwise)\n",
    "> * month_3 is a boolean if the ride is is in March (1 if true, 0 otherwise)\n",
    "> * month_4 is a boolean if the ride is is in April (1 if true, 0 otherwise)\n",
    "> * month_5 is a boolean if the ride is is in May (1 if true, 0 otherwise)\n",
    "> * month_6 is a boolean if the ride is is in June (1 if true, 0 otherwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we have shown you how you can make prediction queries, using REST API calls, to a target deployment engine kdcluster environment that serves your model.\n",
    "\n",
    "Now, follow the instructions in Lab 6 to explore the dynamic aspect of the ML pipeline you have just constructed with KubeDirector. \n",
    "\n",
    "* [Lab 6 Dynamic ML Pipeline](6-WKSHP-K8s-ML-Pipeline-Dynamic-Aspect.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
