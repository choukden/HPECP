{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline with KubeDirector - Lab 6\n",
    "## Dynamic? Did someone say a dynamic ML pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lab workflow**\n",
    "\n",
    "Over time, your model might get stale because of changing traffic conditions and a changing dataset. You may also want to enhance the performance of your model as a result of monitoring the accuracy of the predictions over time. \n",
    "\n",
    "To illustrate the dynamic aspect of the ML pipeline you have just built, letâ€™s imagine you want to improve the prediction accuracy of your model. \n",
    "\n",
    "In this lab: \n",
    "\n",
    "1. You will **retrain** your model by tuning the model parameters to get better predictive performance and save your retrained model into a new file. \n",
    "\n",
    "2. You will then update the model registry information in the configMap kubernetes resource with the file path for the newly trained model file and associated scoring script file. \n",
    "\n",
    "3. You will finally make a new prediction query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1- Initialize the environment**\n",
    "\n",
    "Let's first define the environment variables needed to execute this part of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your studentId is: student75\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# environment variables\n",
    "#\n",
    "studentId=\"student75\" # your Jupyter Notebook student Identifier (i.e.: student<xx>)\n",
    "\n",
    "gateway_host=\"haecpgtw.etc.fr.comm.hpecorp.net\"\n",
    "Internet_access=\"notebooks.hpedev.io\"\n",
    "\n",
    "JupyterNotebookApp=\"cr-cluster-jupyter-notebook.yaml\" # the Jupyter Notebook KD App manifest you will deploy to build your model\n",
    "DeploymentEngineApp=\"cr-cluster-endpoint-wrapper.yaml\" # the Deployment engine KD App manifest you will deploy to query your model for answers \n",
    "PipelineConfigMap=\"ml-pipeline-configmap.yaml\" # ConfigMap manifest used to register the trained model version 1 \n",
    "PipelineConfigMapv2=\"ml-pipeline-configmap-v2.yaml\" # ConfigMap manifest used to register the trained model version 2 \n",
    "#\n",
    "clusterName=\"inference-server-${studentId}\"\n",
    "#\n",
    "# Model registry information\n",
    "#\n",
    "TrainingModel=\"model-${studentId}\"\n",
    "modelVersion=\"1\"\n",
    "#\n",
    "echo \"Your studentId is: \"$studentId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2- Retrain your model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\">Go back to your **local Jupyter Notebook**, Lab Part 3, and run the code cell from the step **\"6-Retrain the model to improve model accuracy\"**.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3- Adjust the model registry information**\n",
    "\n",
    "Once your model is retrained, adjust the model registry information.\n",
    "Run the code cells below to update the model registry information with the path of your **retrained** model file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "  name: model-student75\n",
      "  labels:\n",
      "    kubedirector.hpe.com/cmType: \"model\"\n",
      "data:\n",
      "  name: model-student75\n",
      "  description: \"student75 model\"\n",
      "  model-version: \"1\"\n",
      "  path: /bd-fs-mnt/TenantShare/repo/models/NYCTaxi/student75/XGB.picklev2.dat\n",
      "  scoring-path: /bd-fs-mnt/TenantShare/repo/code/NYCTaxi/student75/XGB_Scoringv2.py"
     ]
    }
   ],
   "source": [
    "cat $PipelineConfigMapv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/model-student75 configured\n"
     ]
    }
   ],
   "source": [
    "kubectl apply -f $PipelineConfigMapv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then, use the command `kubectl describe configmap` below and check the events logged against it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         model-student75\n",
      "Namespace:    k8smltenant\n",
      "Labels:       kubedirector.hpe.com/cmType=model\n",
      "Annotations:  <none>\n",
      "\n",
      "Data\n",
      "====\n",
      "model-version:\n",
      "----\n",
      "1\n",
      "name:\n",
      "----\n",
      "model-student75\n",
      "path:\n",
      "----\n",
      "/bd-fs-mnt/TenantShare/repo/models/NYCTaxi/student75/XGB.picklev2.dat\n",
      "scoring-path:\n",
      "----\n",
      "/bd-fs-mnt/TenantShare/repo/code/NYCTaxi/student75/XGB_Scoringv2.py\n",
      "description:\n",
      "----\n",
      "student75 model\n",
      "Events:\n",
      "  Type    Reason   Age   From          Message\n",
      "  ----    ------   ----  ----          -------\n",
      "  Normal  Cluster  2s    kubedirector  connected to cluster {inference-server-student75}; updating it\n"
     ]
    }
   ],
   "source": [
    "kubectl describe configmap $TrainingModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the events section at the bottom of the command output, you should notice the message:  \n",
    "_\"Connected to cluster {your deployment-engine cluster name}; updating it.\"_ \n",
    "\n",
    ">**Note:** KubeDirector has detected the change of the model registry information. KubeDirector then immediately updates the model registry metadata information on the PODs/Containers of your deployment engine cluster. The deployment engine cluster can therefore reference the newly trained model file to use to serve the prediction requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And use the command `kubectl describe kdcluster` below and check the events logged against it:** \n",
    "\n",
    "In the events section at the bottom of the command output, you should notice the message:  \n",
    "\n",
    "_\"connected configmap has changes, updated context for the PODs of your instance of the deployment engine cluster\"._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         inference-server-student75\n",
      "Namespace:    k8smltenant\n",
      "Labels:       <none>\n",
      "Annotations:  kubedirector.hpe.com/connUpdateCounter: 1\n",
      "              kubedirector.hpe.com/hashChangeCounter: 1\n",
      "API Version:  kubedirector.hpe.com/v1beta1\n",
      "Kind:         KubeDirectorCluster\n",
      "Metadata:\n",
      "  Creation Timestamp:  2021-01-14T07:48:34Z\n",
      "  Finalizers:\n",
      "    kubedirector.hpe.com/cleanup\n",
      "  Generation:        1\n",
      "  Resource Version:  9246316\n",
      "  Self Link:         /apis/kubedirector.hpe.com/v1beta1/namespaces/k8smltenant/kubedirectorclusters/inference-server-student75\n",
      "  UID:               a1b497a0-a5e0-4a81-a2a0-ea41c06adb22\n",
      "Spec:\n",
      "  App:          deployment-engine\n",
      "  App Catalog:  local\n",
      "  Connections:\n",
      "    Configmaps:\n",
      "      model-student75\n",
      "  Naming Scheme:  UID\n",
      "  Roles:\n",
      "    Id:       RESTServer\n",
      "    Members:  1\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "      Requests:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "    Id:          LoadBalancer\n",
      "    Members:     1\n",
      "    Resources:\n",
      "      Limits:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "      Requests:\n",
      "        Cpu:     1\n",
      "        Memory:  2Gi\n",
      "  Service Type:  NodePort\n",
      "Status:\n",
      "  Cluster Service:       kdhs-5pz4s\n",
      "  Generation UID:        dd771ce0-d510-4fd9-9b1b-0bb5083ef193\n",
      "  Last Connection Hash:  1dc280f375b09a67debccc389eb7e47c\n",
      "  Last Node ID:          2\n",
      "  Member State Rollup:\n",
      "    Config Errors:         false\n",
      "    Members Down:          false\n",
      "    Members Initializing:  false\n",
      "    Members Restarting:    false\n",
      "    Members Waiting:       false\n",
      "    Membership Changing:   false\n",
      "  Roles:\n",
      "    Id:  RESTServer\n",
      "    Members:\n",
      "      Auth Token:  bd95fc77c8cb9c851761aa61c6a2b25e\n",
      "      Node ID:     1\n",
      "      Pod:         kdss-cqqxh-0\n",
      "      Service:     s-kdss-cqqxh-0\n",
      "      State:       configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  2\n",
      "        Last Configured Container:    docker://82240eb8506f82e8bda7e3ad2e759cfa1129a13cfef70039eef726f6aefc4909\n",
      "        Last Connection Version:      1\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        2\n",
      "    Stateful Set:                     kdss-cqqxh\n",
      "    Id:                               LoadBalancer\n",
      "    Members:\n",
      "      Auth Token:  f89a4f9489a023631b63d203a2aa57c7\n",
      "      Node ID:     2\n",
      "      Pod:         kdss-lmhpq-0\n",
      "      Service:     s-kdss-lmhpq-0\n",
      "      State:       configured\n",
      "      State Detail:\n",
      "        Last Config Data Generation:  2\n",
      "        Last Configured Container:    docker://2f0a74fd91170f6cd596970e28fc0c18598983e350a8b909d4a320aa511b2c66\n",
      "        Last Connection Version:      1\n",
      "        Last Known Container State:   running\n",
      "        Last Setup Generation:        2\n",
      "    Stateful Set:                     kdss-lmhpq\n",
      "  Spec Generation To Process:         2\n",
      "  State:                              configured\n",
      "Events:\n",
      "  Type    Reason     Age                  From          Message\n",
      "  ----    ------     ----                 ----          -------\n",
      "  Normal  Role       7m4s                 kubedirector  creating role{RESTServer}\n",
      "  Normal  Role       7m4s                 kubedirector  creating role{LoadBalancer}\n",
      "  Normal  Cluster    7m4s                 kubedirector  new\n",
      "  Normal  Role       7m1s                 kubedirector  waiting for replicas count for role{LoadBalancer}: 0 -> 1\n",
      "  Normal  Role       7m1s                 kubedirector  changing replicas count for role{RESTServer}: 0 -> 1\n",
      "  Normal  Role       7m1s                 kubedirector  changing replicas count for role{LoadBalancer}: 0 -> 1\n",
      "  Normal  Role       7m1s                 kubedirector  waiting for replicas count for role{RESTServer}: 0 -> 1\n",
      "  Normal  Member     6m19s                kubedirector  initial config ongoing for member{kdss-cqqxh-0} in role{RESTServer}\n",
      "  Normal  Member     6m                   kubedirector  initial config done for member{kdss-cqqxh-0} in role{RESTServer}\n",
      "  Normal  Member     5m59s (x3 over 6m)   kubedirector  initial config ongoing for member{kdss-lmhpq-0} in role{LoadBalancer}\n",
      "  Normal  Member     5m29s                kubedirector  initial config done for member{kdss-lmhpq-0} in role{LoadBalancer}\n",
      "  Normal  Cluster    50s (x2 over 7m4s)   kubedirector  Annotation initialized to 1\n",
      "  Normal  ConfigMap  50s                  kubedirector  connected configmap {model-student75} has changed\n",
      "  Normal  Cluster    50s                  kubedirector  Updated context\n",
      "  Normal  Cluster    48s                  kubedirector  --reconnect will be called for pod : kdss-cqqxh-0\n",
      "  Normal  Cluster    43s                  kubedirector  --reconnect will be called for pod : kdss-lmhpq-0\n",
      "  Normal  Cluster    41s (x2 over 5m29s)  kubedirector  stable\n"
     ]
    }
   ],
   "source": [
    "kubectl describe kdcluster $clusterName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** By changing the configMap, your entire ML pipeline will be reconciled by KubeDirector operator for you, while the containers of the _deployment engine_ cluster environment remain running. \n",
    "In terms of the use case here, that means you can update existing model registry information or add another model to be handled by the deployment engine without interrupting any current requests that the deployment engine environment is processing.   \n",
    "**The key use of the KubeDirector applications, the KubeDirector clusters, and the KubeDirector Connections capability is what makes your ML pipeline very _dynamic_.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make another query using your retrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"output\": \"The ride duration prediction is 3412.6396 seconds.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Getting the access point for the HAPROXY service of the LoadBalancer (role: LoadBalancer, internal port: 32700)\n",
    "#\n",
    "LoadBalancerURL=$(kubectl describe service -l kubedirector.hpe.com/kdcluster=${clusterName},kubedirector.hpe.com/role=LoadBalancer | grep gateway/32700 | awk '{print $2}')\n",
    "LoadBalancerPort=$(echo $LoadBalancerURL | cut -d':' -f 2) # extract the gateway re-mapped port value.\n",
    "LoadBalancer_endpoint=\"https://$gateway_host:$LoadBalancerPort\"\n",
    "LoadBalancerAuthToken=$(kubectl describe service -l kubedirector.hpe.com/kdcluster=${clusterName},kubedirector.hpe.com/role=LoadBalancer | grep kd-auth-token  | awk '{print $2}' | tr -d '\\r')\n",
    "#\n",
    "# REST API query:\n",
    "#\n",
    "curl --location -k -s --request POST \"${LoadBalancer_endpoint}/${TrainingModel}/${modelVersion}/predict\" \\\n",
    "--header \"X-Auth-Token: ${LoadBalancerAuthToken}\" \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data-raw '{\n",
    "    \"use_scoring\": true,\n",
    "    \"scoring_args\": {\n",
    "        \"work\": 0,\n",
    "        \"start_latitude\": 40.57689727,\n",
    "        \"start_longitude\": -73.99047356,\n",
    "        \"end_latitude\": 40.72058154,\n",
    "        \"end_longitude\": -73.99740673,\n",
    "        \"distance\": 8,\n",
    "        \"weekday\": 1,\n",
    "        \"hour\": 9,\n",
    "        \"month_1\": 0,\n",
    "        \"month_2\": 1,\n",
    "        \"month_3\": 0,\n",
    "        \"month_4\": 0,\n",
    "        \"month_5\": 0,\n",
    "        \"month_6\": 0\n",
    "    }\n",
    "}' | python -m json.tool | grep output | cut -d'\\' -f 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4- Time to go through some cleanup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete your deployment engine, configMap, and your local Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubedirectorcluster.kubedirector.hpe.com \"inference-server-student75\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete -f $DeploymentEngineApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap \"model-student75\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete -f $PipelineConfigMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubedirectorcluster.kubedirector.hpe.com \"jupyter-notebook-student75\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete -f $JupyterNotebookApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how the key use of KubeDirector applications, the KubeDirector clusters, and the KubeDirector Connections capability is what makes your ML pipeline very **dynamic**.\n",
    "\n",
    "* [Conclusion](7-Conclusion.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
